{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN KKKlasifikasi.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3U9OuC1mAtM"
      },
      "source": [
        "# Install Category Encoder and download"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz51ohupgCeX"
      },
      "source": [
        "**Download Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6RU4qdcWmXH",
        "outputId": "a10009e1-8d20-4aa5-bea2-8e83e486a7a6"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/coll-j/Tugas-KK/master/Minggu-3/data.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-21 12:58:44--  https://raw.githubusercontent.com/coll-j/Tugas-KK/master/Minggu-3/data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1475504 (1.4M) [text/plain]\n",
            "Saving to: ‘data.csv’\n",
            "\n",
            "data.csv            100%[===================>]   1.41M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-12-21 12:58:44 (25.7 MB/s) - ‘data.csv’ saved [1475504/1475504]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmXI6numXr7v"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZCLvi06WtMY"
      },
      "source": [
        "# Utils\n",
        "import pandas as pd # Dataframe\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Model related\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn.preprocessing import MinMaxScaler # Normalisasi\n",
        "from sklearn.metrics import accuracy_score # Perhitungan akurasi\n",
        "\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D # Layer CNN\n",
        "from keras.optimizers import Adam # Optimizer\n",
        "from keras.models import Sequential # Model\n",
        "from keras.layers import Dense, Dropout # Layer\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Visualisasi\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAr6T36WpoK9"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oN84_EJDry5Y"
      },
      "source": [
        "**Read data dan assign ke df. Drop kolom `Model` karena tidak akan dipakai**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "0c8HvRrCXudl",
        "outputId": "d5c62765-c889-4143-b85e-baa43653ffdb"
      },
      "source": [
        "df = pd.read_csv('data.csv')\n",
        "df.drop(columns=['Model', 'Market Category'], inplace=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Make</th>\n",
              "      <th>Year</th>\n",
              "      <th>Engine Fuel Type</th>\n",
              "      <th>Engine HP</th>\n",
              "      <th>Engine Cylinders</th>\n",
              "      <th>Transmission Type</th>\n",
              "      <th>Driven_Wheels</th>\n",
              "      <th>Number of Doors</th>\n",
              "      <th>Vehicle Size</th>\n",
              "      <th>Vehicle Style</th>\n",
              "      <th>highway MPG</th>\n",
              "      <th>city mpg</th>\n",
              "      <th>Popularity</th>\n",
              "      <th>MSRP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BMW</td>\n",
              "      <td>2011</td>\n",
              "      <td>premium unleaded (required)</td>\n",
              "      <td>335.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>MANUAL</td>\n",
              "      <td>rear wheel drive</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Compact</td>\n",
              "      <td>Coupe</td>\n",
              "      <td>26</td>\n",
              "      <td>19</td>\n",
              "      <td>3916</td>\n",
              "      <td>46135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BMW</td>\n",
              "      <td>2011</td>\n",
              "      <td>premium unleaded (required)</td>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>MANUAL</td>\n",
              "      <td>rear wheel drive</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Compact</td>\n",
              "      <td>Convertible</td>\n",
              "      <td>28</td>\n",
              "      <td>19</td>\n",
              "      <td>3916</td>\n",
              "      <td>40650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BMW</td>\n",
              "      <td>2011</td>\n",
              "      <td>premium unleaded (required)</td>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>MANUAL</td>\n",
              "      <td>rear wheel drive</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Compact</td>\n",
              "      <td>Coupe</td>\n",
              "      <td>28</td>\n",
              "      <td>20</td>\n",
              "      <td>3916</td>\n",
              "      <td>36350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BMW</td>\n",
              "      <td>2011</td>\n",
              "      <td>premium unleaded (required)</td>\n",
              "      <td>230.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>MANUAL</td>\n",
              "      <td>rear wheel drive</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Compact</td>\n",
              "      <td>Coupe</td>\n",
              "      <td>28</td>\n",
              "      <td>18</td>\n",
              "      <td>3916</td>\n",
              "      <td>29450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BMW</td>\n",
              "      <td>2011</td>\n",
              "      <td>premium unleaded (required)</td>\n",
              "      <td>230.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>MANUAL</td>\n",
              "      <td>rear wheel drive</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Compact</td>\n",
              "      <td>Convertible</td>\n",
              "      <td>28</td>\n",
              "      <td>18</td>\n",
              "      <td>3916</td>\n",
              "      <td>34500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Make  Year             Engine Fuel Type  ...  city mpg  Popularity   MSRP\n",
              "0  BMW  2011  premium unleaded (required)  ...        19        3916  46135\n",
              "1  BMW  2011  premium unleaded (required)  ...        19        3916  40650\n",
              "2  BMW  2011  premium unleaded (required)  ...        20        3916  36350\n",
              "3  BMW  2011  premium unleaded (required)  ...        18        3916  29450\n",
              "4  BMW  2011  premium unleaded (required)  ...        18        3916  34500\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLOLlAckr2X9"
      },
      "source": [
        "**Men-diskritkan fitur kontinu menggunakan qcut dari pandas dengan parameter `pd.qcut(kolom, jumlah_kelas, label)` dan replace kolom target (MSRP) dengan angka. Kolom yang didiskritkan menjadi 3 kelas antara lain:**\n",
        "\n",
        "- **Engine HP**\n",
        "- **highway MPG**\n",
        "- **city mpg**\n",
        "- **Popularity**\n",
        "\n",
        "**Kolom MSRP didiskritkan menjadi 2 kelas murah dan mahal lalu diencode dengan cheap = 0 dan expensive = 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_hUDKbxBPpY",
        "outputId": "6cd9e41e-7e43-4f7a-8db5-45398e867c5c"
      },
      "source": [
        "numeric = []\r\n",
        "for col in df.drop(columns=['Number of Doors']).columns:\r\n",
        "  print(df[col].dtypes)\r\n",
        "  if df[col].dtypes != 'object': # Yang diambil hanya kolom numerik\r\n",
        "    numeric.append(col)\r\n",
        "numeric"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "object\n",
            "int64\n",
            "object\n",
            "float64\n",
            "float64\n",
            "object\n",
            "object\n",
            "object\n",
            "object\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Year',\n",
              " 'Engine HP',\n",
              " 'Engine Cylinders',\n",
              " 'highway MPG',\n",
              " 'city mpg',\n",
              " 'Popularity',\n",
              " 'MSRP']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "sDuNuw9XXzkA",
        "outputId": "93ac5e4b-3a75-42dc-fef5-b1b397115da9"
      },
      "source": [
        "df_disc = df[numeric]\n",
        "\n",
        "df_disc['MSRP'] = pd.qcut(df_disc['MSRP'], 2, labels=['cheap', 'expensive']) # Membagi MSRP antara murah atau mahal, binary\n",
        "df_disc['MSRP'].replace({'cheap': 0, 'expensive': 1}, inplace=True) # mengubah label jadi angka\n",
        "df_disc.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:4582: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Engine HP</th>\n",
              "      <th>Engine Cylinders</th>\n",
              "      <th>highway MPG</th>\n",
              "      <th>city mpg</th>\n",
              "      <th>Popularity</th>\n",
              "      <th>MSRP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011</td>\n",
              "      <td>335.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>26</td>\n",
              "      <td>19</td>\n",
              "      <td>3916</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011</td>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>28</td>\n",
              "      <td>19</td>\n",
              "      <td>3916</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011</td>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>28</td>\n",
              "      <td>20</td>\n",
              "      <td>3916</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011</td>\n",
              "      <td>230.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>28</td>\n",
              "      <td>18</td>\n",
              "      <td>3916</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011</td>\n",
              "      <td>230.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>28</td>\n",
              "      <td>18</td>\n",
              "      <td>3916</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Year  Engine HP  Engine Cylinders  highway MPG  city mpg  Popularity  MSRP\n",
              "0  2011      335.0               6.0           26        19        3916     1\n",
              "1  2011      300.0               6.0           28        19        3916     1\n",
              "2  2011      300.0               6.0           28        20        3916     1\n",
              "3  2011      230.0               6.0           28        18        3916     0\n",
              "4  2011      230.0               6.0           28        18        3916     1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGU_RGs_slW-"
      },
      "source": [
        "**Impute tidak dilakukan, maka semua record yang memiliki null values di-drop. Setelah drop menyisakan `11812` data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "7VrjUw0Jau6W",
        "outputId": "728ced74-93ae-474f-b9d3-27d7ab464b9a"
      },
      "source": [
        "df_disc.dropna(inplace=True) # Drop missing values\n",
        "df_disc.describe(include='all')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Engine HP</th>\n",
              "      <th>Engine Cylinders</th>\n",
              "      <th>highway MPG</th>\n",
              "      <th>city mpg</th>\n",
              "      <th>Popularity</th>\n",
              "      <th>MSRP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>11816.000000</td>\n",
              "      <td>11816.000000</td>\n",
              "      <td>11816.000000</td>\n",
              "      <td>11816.000000</td>\n",
              "      <td>11816.000000</td>\n",
              "      <td>11816.000000</td>\n",
              "      <td>11816.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2010.360190</td>\n",
              "      <td>249.514472</td>\n",
              "      <td>5.650051</td>\n",
              "      <td>26.319736</td>\n",
              "      <td>19.326845</td>\n",
              "      <td>1553.510833</td>\n",
              "      <td>0.496869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7.594077</td>\n",
              "      <td>109.261297</td>\n",
              "      <td>1.752333</td>\n",
              "      <td>7.442964</td>\n",
              "      <td>6.527183</td>\n",
              "      <td>1439.969241</td>\n",
              "      <td>0.500011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1990.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2007.000000</td>\n",
              "      <td>170.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>549.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2015.000000</td>\n",
              "      <td>227.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>1385.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2016.000000</td>\n",
              "      <td>300.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>2009.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2017.000000</td>\n",
              "      <td>1001.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>354.000000</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>5657.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Year     Engine HP  ...    Popularity          MSRP\n",
              "count  11816.000000  11816.000000  ...  11816.000000  11816.000000\n",
              "mean    2010.360190    249.514472  ...   1553.510833      0.496869\n",
              "std        7.594077    109.261297  ...   1439.969241      0.500011\n",
              "min     1990.000000     55.000000  ...      2.000000      0.000000\n",
              "25%     2007.000000    170.000000  ...    549.000000      0.000000\n",
              "50%     2015.000000    227.000000  ...   1385.000000      0.000000\n",
              "75%     2016.000000    300.000000  ...   2009.000000      1.000000\n",
              "max     2017.000000   1001.000000  ...   5657.000000      1.000000\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "PZ5ynT0ADdbJ",
        "outputId": "6de17b34-7f94-4cb9-e0de-fdeae518585d"
      },
      "source": [
        "X, y = df_disc.drop(columns=['MSRP']), df_disc['MSRP'] # Membagi data antara input (X) dan output (y)\r\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Engine HP</th>\n",
              "      <th>Engine Cylinders</th>\n",
              "      <th>highway MPG</th>\n",
              "      <th>city mpg</th>\n",
              "      <th>Popularity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011</td>\n",
              "      <td>335.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>26</td>\n",
              "      <td>19</td>\n",
              "      <td>3916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011</td>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>28</td>\n",
              "      <td>19</td>\n",
              "      <td>3916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011</td>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>28</td>\n",
              "      <td>20</td>\n",
              "      <td>3916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011</td>\n",
              "      <td>230.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>28</td>\n",
              "      <td>18</td>\n",
              "      <td>3916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011</td>\n",
              "      <td>230.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>28</td>\n",
              "      <td>18</td>\n",
              "      <td>3916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11909</th>\n",
              "      <td>2012</td>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>23</td>\n",
              "      <td>16</td>\n",
              "      <td>204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11910</th>\n",
              "      <td>2012</td>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>23</td>\n",
              "      <td>16</td>\n",
              "      <td>204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11911</th>\n",
              "      <td>2012</td>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>23</td>\n",
              "      <td>16</td>\n",
              "      <td>204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11912</th>\n",
              "      <td>2013</td>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>23</td>\n",
              "      <td>16</td>\n",
              "      <td>204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11913</th>\n",
              "      <td>2006</td>\n",
              "      <td>221.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>26</td>\n",
              "      <td>17</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11816 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Year  Engine HP  Engine Cylinders  highway MPG  city mpg  Popularity\n",
              "0      2011      335.0               6.0           26        19        3916\n",
              "1      2011      300.0               6.0           28        19        3916\n",
              "2      2011      300.0               6.0           28        20        3916\n",
              "3      2011      230.0               6.0           28        18        3916\n",
              "4      2011      230.0               6.0           28        18        3916\n",
              "...     ...        ...               ...          ...       ...         ...\n",
              "11909  2012      300.0               6.0           23        16         204\n",
              "11910  2012      300.0               6.0           23        16         204\n",
              "11911  2012      300.0               6.0           23        16         204\n",
              "11912  2013      300.0               6.0           23        16         204\n",
              "11913  2006      221.0               6.0           26        17          61\n",
              "\n",
              "[11816 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoYUsncEC_dP"
      },
      "source": [
        "# Normalisasi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2wyReT6C_Nd",
        "outputId": "3e879db8-2dda-44d9-af73-c6a2d9d6634e"
      },
      "source": [
        "# Normalisasi\r\n",
        "scaler = MinMaxScaler() # Range 0-1\r\n",
        "X_scaled = scaler.fit_transform(X)\r\n",
        "X_scaled"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.77777778, 0.29598309, 0.375     , 0.04093567, 0.09230769,\n",
              "        0.69213086],\n",
              "       [0.77777778, 0.2589852 , 0.375     , 0.04678363, 0.09230769,\n",
              "        0.69213086],\n",
              "       [0.77777778, 0.2589852 , 0.375     , 0.04678363, 0.1       ,\n",
              "        0.69213086],\n",
              "       ...,\n",
              "       [0.81481481, 0.2589852 , 0.375     , 0.03216374, 0.06923077,\n",
              "        0.0357206 ],\n",
              "       [0.85185185, 0.2589852 , 0.375     , 0.03216374, 0.06923077,\n",
              "        0.0357206 ],\n",
              "       [0.59259259, 0.17547569, 0.375     , 0.04093567, 0.07692308,\n",
              "        0.01043324]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEBoaGUMvjpu"
      },
      "source": [
        "# Training\n",
        "\n",
        "**Dalam proses training dicoba dengan beberapa ukuran training yang ditentukan oleh ukuran data testing.**\n",
        "\n",
        "> jumlah data training = jumlah keseluruhan data - jumlah data testing\n",
        "\n",
        "**Jumlah data testing direpresentasikan dalam presentase sehingga jika di-tablekan menjadi:**\n",
        "\n",
        "> testing | training\n",
        "> --- | ---\n",
        "> 0.6 | 0.4\n",
        "> 0.5 | 0.5\n",
        "> 0.4 | 0.6\n",
        "> 0.3 | 0.7\n",
        "\n",
        "**Alur percobaan dilakukan dengan looping setiap parameter model:**\n",
        "1. Inisiasi model\n",
        "2. Fitting model terhadap data training\n",
        "3. Prediksi model terhadap data testing\n",
        "4. Perhitungan akurasi dan f1 terhadap data testing\n",
        "5. Pemilihan parameter terbaik sesuai akurasi dari data testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13d4KuDmA-YG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8911330-b8f2-4e85-9456-3a66677f0ac8"
      },
      "source": [
        "# Splitting data untuk training dan testing\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\r\n",
        "print(len(X_train), len(y_train), len(X_test), len(y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8271 8271 3545 3545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "218Gw4BnNG3P",
        "outputId": "66cdd069-9ad8-47c9-a1f6-9bcb452d30c0"
      },
      "source": [
        "# Mengubah dimensi input agar menjadi 3 dimensi\r\n",
        "# Karena Conv1D menerima input dalam dimensi minimal 3\r\n",
        "X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\r\n",
        "X_train_reshaped.shape[1:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2ookz1KNzvS",
        "outputId": "4ea167eb-9b64-4e90-dca8-cd647e4569a5"
      },
      "source": [
        "# Sama dengan atas, untuk data testing\r\n",
        "X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\r\n",
        "X_test_reshaped.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3545, 6, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bkjmA5kEIa_",
        "outputId": "c07eaeb2-8ea0-425c-f437-a035e62c440c"
      },
      "source": [
        "model = Sequential()\r\n",
        "# Hidden layer 1\r\n",
        "model.add(Conv1D(32, 4, input_shape=X_train_reshaped.shape[1:3], activation='relu'))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "\r\n",
        "# Hidden Layer 2\r\n",
        "model.add(Conv1D(16, 2))\r\n",
        "model.add(Dropout(0.3))\r\n",
        "\r\n",
        "# Hidden Layer 3\r\n",
        "# model.add(Conv1D(32, 2))\r\n",
        "# model.add(Dropout(0.3))\r\n",
        "\r\n",
        "# Output layer\r\n",
        "model.add(MaxPooling1D(2))\r\n",
        "model.add(Dense(1, activation='sigmoid'))\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_2 (Conv1D)            (None, 3, 32)             160       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 32)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 2, 16)             1040      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2, 16)             0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 1, 16)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1, 1)              17        \n",
            "=================================================================\n",
            "Total params: 1,217\n",
            "Trainable params: 1,217\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX0j5vZCLz4U"
      },
      "source": [
        "lr = 0.001\r\n",
        "optimizer = Adam(learning_rate=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGXvIV4VA3Pg"
      },
      "source": [
        "early_stopping_monitor = EarlyStopping(\n",
        "    monitor='accuracy', # Stopping berdasarkan akurasi\n",
        "    min_delta=0,\n",
        "    patience=100, # Stopping setelah 100 iterasi tidak ada peningkatan akurasi\n",
        "    verbose=0,\n",
        "    mode='auto',\n",
        "    baseline=None,\n",
        "    restore_best_weights=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4us3bxrhMFuP",
        "outputId": "40dc82ae-d035-4a71-ccaa-7703ea4b73f7"
      },
      "source": [
        "%%timeit -n 1\r\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics='accuracy')\r\n",
        "history = model.fit(X_train_reshaped, y_train, # Data training\r\n",
        "          epochs=1000, \r\n",
        "          batch_size=32, \r\n",
        "          verbose=1, # Print progres\r\n",
        "          validation_data=(X_test_reshaped, y_test), # Data Validasi\r\n",
        "          callbacks=[early_stopping_monitor])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.6463 - accuracy: 0.6210 - val_loss: 0.4129 - val_accuracy: 0.8409\n",
            "Epoch 2/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.4141 - accuracy: 0.8238 - val_loss: 0.3382 - val_accuracy: 0.8415\n",
            "Epoch 3/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.3633 - accuracy: 0.8444 - val_loss: 0.3229 - val_accuracy: 0.8446\n",
            "Epoch 4/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.3654 - accuracy: 0.8456 - val_loss: 0.3124 - val_accuracy: 0.8660\n",
            "Epoch 5/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.3462 - accuracy: 0.8519 - val_loss: 0.3021 - val_accuracy: 0.8621\n",
            "Epoch 6/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.3382 - accuracy: 0.8603 - val_loss: 0.2961 - val_accuracy: 0.8722\n",
            "Epoch 7/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.3342 - accuracy: 0.8631 - val_loss: 0.2939 - val_accuracy: 0.8858\n",
            "Epoch 8/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.3285 - accuracy: 0.8695 - val_loss: 0.2871 - val_accuracy: 0.8750\n",
            "Epoch 9/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.3138 - accuracy: 0.8739 - val_loss: 0.2836 - val_accuracy: 0.8843\n",
            "Epoch 10/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.3158 - accuracy: 0.8691 - val_loss: 0.2815 - val_accuracy: 0.8722\n",
            "Epoch 11/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.3176 - accuracy: 0.8733 - val_loss: 0.2823 - val_accuracy: 0.8889\n",
            "Epoch 12/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.3058 - accuracy: 0.8760 - val_loss: 0.2810 - val_accuracy: 0.8880\n",
            "Epoch 13/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.3043 - accuracy: 0.8756 - val_loss: 0.2741 - val_accuracy: 0.8779\n",
            "Epoch 14/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.3080 - accuracy: 0.8769 - val_loss: 0.2737 - val_accuracy: 0.8874\n",
            "Epoch 15/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.3020 - accuracy: 0.8789 - val_loss: 0.2684 - val_accuracy: 0.8874\n",
            "Epoch 16/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2975 - accuracy: 0.8752 - val_loss: 0.2703 - val_accuracy: 0.8869\n",
            "Epoch 17/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2913 - accuracy: 0.8791 - val_loss: 0.2716 - val_accuracy: 0.8894\n",
            "Epoch 18/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2889 - accuracy: 0.8832 - val_loss: 0.2696 - val_accuracy: 0.8852\n",
            "Epoch 19/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2827 - accuracy: 0.8849 - val_loss: 0.2760 - val_accuracy: 0.8934\n",
            "Epoch 20/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2841 - accuracy: 0.8813 - val_loss: 0.2711 - val_accuracy: 0.8911\n",
            "Epoch 21/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2903 - accuracy: 0.8808 - val_loss: 0.2655 - val_accuracy: 0.8869\n",
            "Epoch 22/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2844 - accuracy: 0.8861 - val_loss: 0.2696 - val_accuracy: 0.8900\n",
            "Epoch 23/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2992 - accuracy: 0.8799 - val_loss: 0.2627 - val_accuracy: 0.8872\n",
            "Epoch 24/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2884 - accuracy: 0.8796 - val_loss: 0.2655 - val_accuracy: 0.8891\n",
            "Epoch 25/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2843 - accuracy: 0.8853 - val_loss: 0.2655 - val_accuracy: 0.8906\n",
            "Epoch 26/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2885 - accuracy: 0.8823 - val_loss: 0.2771 - val_accuracy: 0.8953\n",
            "Epoch 27/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2910 - accuracy: 0.8798 - val_loss: 0.2610 - val_accuracy: 0.8889\n",
            "Epoch 28/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2949 - accuracy: 0.8803 - val_loss: 0.2596 - val_accuracy: 0.8894\n",
            "Epoch 29/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2837 - accuracy: 0.8796 - val_loss: 0.2597 - val_accuracy: 0.8832\n",
            "Epoch 30/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2826 - accuracy: 0.8849 - val_loss: 0.2622 - val_accuracy: 0.8818\n",
            "Epoch 31/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2786 - accuracy: 0.8817 - val_loss: 0.2660 - val_accuracy: 0.8956\n",
            "Epoch 32/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2888 - accuracy: 0.8848 - val_loss: 0.2586 - val_accuracy: 0.8810\n",
            "Epoch 33/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2840 - accuracy: 0.8846 - val_loss: 0.2599 - val_accuracy: 0.8852\n",
            "Epoch 34/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2863 - accuracy: 0.8840 - val_loss: 0.2618 - val_accuracy: 0.8906\n",
            "Epoch 35/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2819 - accuracy: 0.8819 - val_loss: 0.2599 - val_accuracy: 0.8917\n",
            "Epoch 36/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2785 - accuracy: 0.8831 - val_loss: 0.2580 - val_accuracy: 0.8908\n",
            "Epoch 37/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2813 - accuracy: 0.8846 - val_loss: 0.2613 - val_accuracy: 0.8920\n",
            "Epoch 38/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2893 - accuracy: 0.8836 - val_loss: 0.2568 - val_accuracy: 0.8920\n",
            "Epoch 39/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2766 - accuracy: 0.8912 - val_loss: 0.2605 - val_accuracy: 0.8939\n",
            "Epoch 40/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2827 - accuracy: 0.8840 - val_loss: 0.2582 - val_accuracy: 0.8928\n",
            "Epoch 41/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2709 - accuracy: 0.8902 - val_loss: 0.2564 - val_accuracy: 0.8903\n",
            "Epoch 42/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2927 - accuracy: 0.8795 - val_loss: 0.2646 - val_accuracy: 0.8906\n",
            "Epoch 43/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2862 - accuracy: 0.8873 - val_loss: 0.2644 - val_accuracy: 0.8934\n",
            "Epoch 44/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2917 - accuracy: 0.8782 - val_loss: 0.2565 - val_accuracy: 0.8860\n",
            "Epoch 45/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2853 - accuracy: 0.8835 - val_loss: 0.2564 - val_accuracy: 0.8883\n",
            "Epoch 46/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2836 - accuracy: 0.8847 - val_loss: 0.2564 - val_accuracy: 0.8900\n",
            "Epoch 47/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2833 - accuracy: 0.8790 - val_loss: 0.2565 - val_accuracy: 0.8925\n",
            "Epoch 48/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2786 - accuracy: 0.8831 - val_loss: 0.2579 - val_accuracy: 0.8911\n",
            "Epoch 49/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2654 - accuracy: 0.8876 - val_loss: 0.2552 - val_accuracy: 0.8934\n",
            "Epoch 50/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2770 - accuracy: 0.8878 - val_loss: 0.2556 - val_accuracy: 0.8931\n",
            "Epoch 51/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2843 - accuracy: 0.8879 - val_loss: 0.2538 - val_accuracy: 0.8934\n",
            "Epoch 52/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2859 - accuracy: 0.8841 - val_loss: 0.2562 - val_accuracy: 0.8922\n",
            "Epoch 53/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2889 - accuracy: 0.8800 - val_loss: 0.2547 - val_accuracy: 0.8863\n",
            "Epoch 54/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2879 - accuracy: 0.8849 - val_loss: 0.2580 - val_accuracy: 0.8922\n",
            "Epoch 55/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2936 - accuracy: 0.8800 - val_loss: 0.2534 - val_accuracy: 0.8846\n",
            "Epoch 56/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2836 - accuracy: 0.8849 - val_loss: 0.2556 - val_accuracy: 0.8866\n",
            "Epoch 57/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2737 - accuracy: 0.8848 - val_loss: 0.2542 - val_accuracy: 0.8860\n",
            "Epoch 58/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2688 - accuracy: 0.8894 - val_loss: 0.2546 - val_accuracy: 0.8937\n",
            "Epoch 59/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2725 - accuracy: 0.8903 - val_loss: 0.2543 - val_accuracy: 0.8920\n",
            "Epoch 60/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2787 - accuracy: 0.8886 - val_loss: 0.2562 - val_accuracy: 0.8869\n",
            "Epoch 61/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2753 - accuracy: 0.8843 - val_loss: 0.2578 - val_accuracy: 0.8925\n",
            "Epoch 62/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2780 - accuracy: 0.8824 - val_loss: 0.2598 - val_accuracy: 0.8917\n",
            "Epoch 63/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2750 - accuracy: 0.8909 - val_loss: 0.2610 - val_accuracy: 0.8939\n",
            "Epoch 64/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2665 - accuracy: 0.8948 - val_loss: 0.2540 - val_accuracy: 0.8846\n",
            "Epoch 65/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2778 - accuracy: 0.8854 - val_loss: 0.2543 - val_accuracy: 0.8906\n",
            "Epoch 66/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2761 - accuracy: 0.8852 - val_loss: 0.2533 - val_accuracy: 0.8869\n",
            "Epoch 67/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2779 - accuracy: 0.8875 - val_loss: 0.2565 - val_accuracy: 0.8874\n",
            "Epoch 68/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2759 - accuracy: 0.8862 - val_loss: 0.2566 - val_accuracy: 0.8920\n",
            "Epoch 69/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2751 - accuracy: 0.8898 - val_loss: 0.2532 - val_accuracy: 0.8858\n",
            "Epoch 70/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2764 - accuracy: 0.8850 - val_loss: 0.2645 - val_accuracy: 0.8948\n",
            "Epoch 71/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2665 - accuracy: 0.8916 - val_loss: 0.2526 - val_accuracy: 0.8891\n",
            "Epoch 72/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2804 - accuracy: 0.8793 - val_loss: 0.2536 - val_accuracy: 0.8858\n",
            "Epoch 73/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2766 - accuracy: 0.8843 - val_loss: 0.2589 - val_accuracy: 0.8922\n",
            "Epoch 74/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2778 - accuracy: 0.8848 - val_loss: 0.2520 - val_accuracy: 0.8855\n",
            "Epoch 75/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2716 - accuracy: 0.8856 - val_loss: 0.2580 - val_accuracy: 0.8948\n",
            "Epoch 76/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2843 - accuracy: 0.8808 - val_loss: 0.2573 - val_accuracy: 0.8922\n",
            "Epoch 77/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2779 - accuracy: 0.8811 - val_loss: 0.2531 - val_accuracy: 0.8874\n",
            "Epoch 78/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2757 - accuracy: 0.8865 - val_loss: 0.2540 - val_accuracy: 0.8877\n",
            "Epoch 79/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2753 - accuracy: 0.8883 - val_loss: 0.2527 - val_accuracy: 0.8883\n",
            "Epoch 80/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2763 - accuracy: 0.8860 - val_loss: 0.2528 - val_accuracy: 0.8931\n",
            "Epoch 81/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2707 - accuracy: 0.8875 - val_loss: 0.2539 - val_accuracy: 0.8931\n",
            "Epoch 82/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2818 - accuracy: 0.8852 - val_loss: 0.2498 - val_accuracy: 0.8866\n",
            "Epoch 83/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2907 - accuracy: 0.8810 - val_loss: 0.2509 - val_accuracy: 0.8937\n",
            "Epoch 84/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2646 - accuracy: 0.8922 - val_loss: 0.2547 - val_accuracy: 0.8931\n",
            "Epoch 85/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2617 - accuracy: 0.8934 - val_loss: 0.2551 - val_accuracy: 0.8945\n",
            "Epoch 86/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2735 - accuracy: 0.8878 - val_loss: 0.2497 - val_accuracy: 0.8900\n",
            "Epoch 87/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2707 - accuracy: 0.8808 - val_loss: 0.2514 - val_accuracy: 0.8894\n",
            "Epoch 88/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2789 - accuracy: 0.8832 - val_loss: 0.2532 - val_accuracy: 0.8937\n",
            "Epoch 89/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2700 - accuracy: 0.8890 - val_loss: 0.2519 - val_accuracy: 0.8874\n",
            "Epoch 90/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2685 - accuracy: 0.8889 - val_loss: 0.2509 - val_accuracy: 0.8945\n",
            "Epoch 91/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2699 - accuracy: 0.8948 - val_loss: 0.2528 - val_accuracy: 0.8939\n",
            "Epoch 92/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2794 - accuracy: 0.8818 - val_loss: 0.2688 - val_accuracy: 0.8925\n",
            "Epoch 93/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2737 - accuracy: 0.8880 - val_loss: 0.2515 - val_accuracy: 0.8917\n",
            "Epoch 94/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2626 - accuracy: 0.8890 - val_loss: 0.2523 - val_accuracy: 0.8855\n",
            "Epoch 95/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2715 - accuracy: 0.8848 - val_loss: 0.2526 - val_accuracy: 0.8945\n",
            "Epoch 96/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2733 - accuracy: 0.8850 - val_loss: 0.2558 - val_accuracy: 0.8928\n",
            "Epoch 97/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2794 - accuracy: 0.8844 - val_loss: 0.2545 - val_accuracy: 0.8869\n",
            "Epoch 98/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2824 - accuracy: 0.8886 - val_loss: 0.2519 - val_accuracy: 0.8920\n",
            "Epoch 99/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2741 - accuracy: 0.8862 - val_loss: 0.2504 - val_accuracy: 0.8886\n",
            "Epoch 100/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2705 - accuracy: 0.8868 - val_loss: 0.2514 - val_accuracy: 0.8922\n",
            "Epoch 101/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2712 - accuracy: 0.8856 - val_loss: 0.2535 - val_accuracy: 0.8934\n",
            "Epoch 102/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2676 - accuracy: 0.8910 - val_loss: 0.2535 - val_accuracy: 0.8948\n",
            "Epoch 103/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2683 - accuracy: 0.8935 - val_loss: 0.2510 - val_accuracy: 0.8914\n",
            "Epoch 104/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2786 - accuracy: 0.8849 - val_loss: 0.2550 - val_accuracy: 0.8951\n",
            "Epoch 105/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2712 - accuracy: 0.8848 - val_loss: 0.2555 - val_accuracy: 0.8945\n",
            "Epoch 106/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2862 - accuracy: 0.8815 - val_loss: 0.2535 - val_accuracy: 0.8880\n",
            "Epoch 107/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2761 - accuracy: 0.8860 - val_loss: 0.2531 - val_accuracy: 0.8942\n",
            "Epoch 108/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2660 - accuracy: 0.8942 - val_loss: 0.2526 - val_accuracy: 0.8911\n",
            "Epoch 109/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2836 - accuracy: 0.8850 - val_loss: 0.2521 - val_accuracy: 0.8914\n",
            "Epoch 110/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2748 - accuracy: 0.8831 - val_loss: 0.2501 - val_accuracy: 0.8894\n",
            "Epoch 111/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2678 - accuracy: 0.8892 - val_loss: 0.2512 - val_accuracy: 0.8948\n",
            "Epoch 112/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2697 - accuracy: 0.8903 - val_loss: 0.2505 - val_accuracy: 0.8908\n",
            "Epoch 113/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2751 - accuracy: 0.8904 - val_loss: 0.2540 - val_accuracy: 0.8942\n",
            "Epoch 114/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2646 - accuracy: 0.8940 - val_loss: 0.2553 - val_accuracy: 0.8922\n",
            "Epoch 115/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2670 - accuracy: 0.8958 - val_loss: 0.2502 - val_accuracy: 0.8914\n",
            "Epoch 116/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2714 - accuracy: 0.8861 - val_loss: 0.2520 - val_accuracy: 0.8914\n",
            "Epoch 117/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2823 - accuracy: 0.8864 - val_loss: 0.2562 - val_accuracy: 0.8920\n",
            "Epoch 118/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2761 - accuracy: 0.8903 - val_loss: 0.2539 - val_accuracy: 0.8911\n",
            "Epoch 119/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2820 - accuracy: 0.8818 - val_loss: 0.2520 - val_accuracy: 0.8911\n",
            "Epoch 120/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2845 - accuracy: 0.8807 - val_loss: 0.2660 - val_accuracy: 0.8937\n",
            "Epoch 121/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2868 - accuracy: 0.8812 - val_loss: 0.2558 - val_accuracy: 0.8925\n",
            "Epoch 122/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2638 - accuracy: 0.8883 - val_loss: 0.2540 - val_accuracy: 0.8948\n",
            "Epoch 123/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2733 - accuracy: 0.8847 - val_loss: 0.2494 - val_accuracy: 0.8908\n",
            "Epoch 124/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2795 - accuracy: 0.8866 - val_loss: 0.2492 - val_accuracy: 0.8917\n",
            "Epoch 125/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2808 - accuracy: 0.8839 - val_loss: 0.2507 - val_accuracy: 0.8869\n",
            "Epoch 126/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2751 - accuracy: 0.8868 - val_loss: 0.2541 - val_accuracy: 0.8841\n",
            "Epoch 127/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2866 - accuracy: 0.8825 - val_loss: 0.2500 - val_accuracy: 0.8843\n",
            "Epoch 128/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2741 - accuracy: 0.8850 - val_loss: 0.2507 - val_accuracy: 0.8942\n",
            "Epoch 129/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2739 - accuracy: 0.8879 - val_loss: 0.2632 - val_accuracy: 0.8939\n",
            "Epoch 130/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2763 - accuracy: 0.8849 - val_loss: 0.2478 - val_accuracy: 0.8874\n",
            "Epoch 131/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2688 - accuracy: 0.8885 - val_loss: 0.2524 - val_accuracy: 0.8925\n",
            "Epoch 132/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2773 - accuracy: 0.8813 - val_loss: 0.2512 - val_accuracy: 0.8911\n",
            "Epoch 133/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2752 - accuracy: 0.8876 - val_loss: 0.2501 - val_accuracy: 0.8894\n",
            "Epoch 134/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2738 - accuracy: 0.8848 - val_loss: 0.2525 - val_accuracy: 0.8860\n",
            "Epoch 135/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2627 - accuracy: 0.8938 - val_loss: 0.2503 - val_accuracy: 0.8931\n",
            "Epoch 136/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2829 - accuracy: 0.8826 - val_loss: 0.2508 - val_accuracy: 0.8911\n",
            "Epoch 137/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2592 - accuracy: 0.8930 - val_loss: 0.2518 - val_accuracy: 0.8931\n",
            "Epoch 138/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2834 - accuracy: 0.8812 - val_loss: 0.2529 - val_accuracy: 0.8931\n",
            "Epoch 139/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2688 - accuracy: 0.8920 - val_loss: 0.2496 - val_accuracy: 0.8922\n",
            "Epoch 140/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2576 - accuracy: 0.8906 - val_loss: 0.2492 - val_accuracy: 0.8903\n",
            "Epoch 141/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2819 - accuracy: 0.8858 - val_loss: 0.2487 - val_accuracy: 0.8939\n",
            "Epoch 142/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2829 - accuracy: 0.8831 - val_loss: 0.2631 - val_accuracy: 0.8953\n",
            "Epoch 143/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2755 - accuracy: 0.8891 - val_loss: 0.2613 - val_accuracy: 0.8953\n",
            "Epoch 144/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2615 - accuracy: 0.8950 - val_loss: 0.2541 - val_accuracy: 0.8934\n",
            "Epoch 145/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2685 - accuracy: 0.8887 - val_loss: 0.2489 - val_accuracy: 0.8917\n",
            "Epoch 146/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2726 - accuracy: 0.8861 - val_loss: 0.2555 - val_accuracy: 0.8948\n",
            "Epoch 147/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2643 - accuracy: 0.8896 - val_loss: 0.2482 - val_accuracy: 0.8920\n",
            "Epoch 148/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2729 - accuracy: 0.8885 - val_loss: 0.2488 - val_accuracy: 0.8945\n",
            "Epoch 149/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2834 - accuracy: 0.8865 - val_loss: 0.2590 - val_accuracy: 0.8953\n",
            "Epoch 150/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2752 - accuracy: 0.8846 - val_loss: 0.2496 - val_accuracy: 0.8894\n",
            "Epoch 151/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2682 - accuracy: 0.8887 - val_loss: 0.2475 - val_accuracy: 0.8931\n",
            "Epoch 152/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2670 - accuracy: 0.8942 - val_loss: 0.2488 - val_accuracy: 0.8951\n",
            "Epoch 153/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2746 - accuracy: 0.8876 - val_loss: 0.2533 - val_accuracy: 0.8863\n",
            "Epoch 154/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2769 - accuracy: 0.8877 - val_loss: 0.2489 - val_accuracy: 0.8928\n",
            "Epoch 155/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2699 - accuracy: 0.8924 - val_loss: 0.2490 - val_accuracy: 0.8951\n",
            "Epoch 156/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2751 - accuracy: 0.8851 - val_loss: 0.2487 - val_accuracy: 0.8937\n",
            "Epoch 157/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2703 - accuracy: 0.8920 - val_loss: 0.2512 - val_accuracy: 0.8953\n",
            "Epoch 158/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2644 - accuracy: 0.8871 - val_loss: 0.2497 - val_accuracy: 0.8886\n",
            "Epoch 159/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2726 - accuracy: 0.8874 - val_loss: 0.2504 - val_accuracy: 0.8956\n",
            "Epoch 160/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2730 - accuracy: 0.8880 - val_loss: 0.2505 - val_accuracy: 0.8900\n",
            "Epoch 161/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2633 - accuracy: 0.8879 - val_loss: 0.2497 - val_accuracy: 0.8953\n",
            "Epoch 162/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2557 - accuracy: 0.9005 - val_loss: 0.2490 - val_accuracy: 0.8903\n",
            "Epoch 163/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2717 - accuracy: 0.8849 - val_loss: 0.2660 - val_accuracy: 0.8968\n",
            "Epoch 164/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2644 - accuracy: 0.8930 - val_loss: 0.2464 - val_accuracy: 0.8886\n",
            "Epoch 165/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2804 - accuracy: 0.8850 - val_loss: 0.2513 - val_accuracy: 0.8934\n",
            "Epoch 166/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2727 - accuracy: 0.8822 - val_loss: 0.2497 - val_accuracy: 0.8945\n",
            "Epoch 167/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2740 - accuracy: 0.8873 - val_loss: 0.2542 - val_accuracy: 0.8945\n",
            "Epoch 168/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2773 - accuracy: 0.8891 - val_loss: 0.2484 - val_accuracy: 0.8880\n",
            "Epoch 169/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2640 - accuracy: 0.8912 - val_loss: 0.2476 - val_accuracy: 0.8942\n",
            "Epoch 170/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2635 - accuracy: 0.8941 - val_loss: 0.2571 - val_accuracy: 0.8956\n",
            "Epoch 171/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2701 - accuracy: 0.8859 - val_loss: 0.2484 - val_accuracy: 0.8886\n",
            "Epoch 172/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2628 - accuracy: 0.8929 - val_loss: 0.2486 - val_accuracy: 0.8886\n",
            "Epoch 173/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2772 - accuracy: 0.8829 - val_loss: 0.2501 - val_accuracy: 0.8922\n",
            "Epoch 174/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2713 - accuracy: 0.8896 - val_loss: 0.2494 - val_accuracy: 0.8922\n",
            "Epoch 175/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2811 - accuracy: 0.8804 - val_loss: 0.2479 - val_accuracy: 0.8872\n",
            "Epoch 176/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2632 - accuracy: 0.8936 - val_loss: 0.2472 - val_accuracy: 0.8906\n",
            "Epoch 177/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2717 - accuracy: 0.8882 - val_loss: 0.2491 - val_accuracy: 0.8928\n",
            "Epoch 178/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2755 - accuracy: 0.8867 - val_loss: 0.2506 - val_accuracy: 0.8962\n",
            "Epoch 179/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2682 - accuracy: 0.8896 - val_loss: 0.2475 - val_accuracy: 0.8908\n",
            "Epoch 180/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2682 - accuracy: 0.8852 - val_loss: 0.2484 - val_accuracy: 0.8886\n",
            "Epoch 181/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2752 - accuracy: 0.8872 - val_loss: 0.2517 - val_accuracy: 0.8931\n",
            "Epoch 182/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2653 - accuracy: 0.8908 - val_loss: 0.2482 - val_accuracy: 0.8951\n",
            "Epoch 183/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2682 - accuracy: 0.8892 - val_loss: 0.2482 - val_accuracy: 0.8937\n",
            "Epoch 184/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2806 - accuracy: 0.8858 - val_loss: 0.2552 - val_accuracy: 0.8872\n",
            "Epoch 185/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2598 - accuracy: 0.8908 - val_loss: 0.2501 - val_accuracy: 0.8920\n",
            "Epoch 186/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2741 - accuracy: 0.8863 - val_loss: 0.2480 - val_accuracy: 0.8894\n",
            "Epoch 187/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2733 - accuracy: 0.8904 - val_loss: 0.2474 - val_accuracy: 0.8934\n",
            "Epoch 188/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2803 - accuracy: 0.8849 - val_loss: 0.2545 - val_accuracy: 0.8934\n",
            "Epoch 189/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2592 - accuracy: 0.8935 - val_loss: 0.2554 - val_accuracy: 0.8942\n",
            "Epoch 190/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2794 - accuracy: 0.8884 - val_loss: 0.2516 - val_accuracy: 0.8948\n",
            "Epoch 191/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2739 - accuracy: 0.8860 - val_loss: 0.2475 - val_accuracy: 0.8883\n",
            "Epoch 192/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2822 - accuracy: 0.8852 - val_loss: 0.2464 - val_accuracy: 0.8934\n",
            "Epoch 193/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2725 - accuracy: 0.8878 - val_loss: 0.2481 - val_accuracy: 0.8922\n",
            "Epoch 194/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2762 - accuracy: 0.8838 - val_loss: 0.2508 - val_accuracy: 0.8948\n",
            "Epoch 195/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2663 - accuracy: 0.8946 - val_loss: 0.2472 - val_accuracy: 0.8858\n",
            "Epoch 196/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2689 - accuracy: 0.8943 - val_loss: 0.2506 - val_accuracy: 0.8937\n",
            "Epoch 197/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2730 - accuracy: 0.8884 - val_loss: 0.2471 - val_accuracy: 0.8880\n",
            "Epoch 198/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2771 - accuracy: 0.8857 - val_loss: 0.2520 - val_accuracy: 0.8928\n",
            "Epoch 199/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2745 - accuracy: 0.8861 - val_loss: 0.2478 - val_accuracy: 0.8869\n",
            "Epoch 200/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2765 - accuracy: 0.8851 - val_loss: 0.2488 - val_accuracy: 0.8900\n",
            "Epoch 201/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2636 - accuracy: 0.8945 - val_loss: 0.2459 - val_accuracy: 0.8931\n",
            "Epoch 202/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2682 - accuracy: 0.8878 - val_loss: 0.2489 - val_accuracy: 0.8911\n",
            "Epoch 203/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2675 - accuracy: 0.8896 - val_loss: 0.2482 - val_accuracy: 0.8948\n",
            "Epoch 204/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2828 - accuracy: 0.8824 - val_loss: 0.2476 - val_accuracy: 0.8928\n",
            "Epoch 205/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2621 - accuracy: 0.8891 - val_loss: 0.2477 - val_accuracy: 0.8948\n",
            "Epoch 206/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2860 - accuracy: 0.8820 - val_loss: 0.2478 - val_accuracy: 0.8891\n",
            "Epoch 207/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2736 - accuracy: 0.8960 - val_loss: 0.2519 - val_accuracy: 0.8931\n",
            "Epoch 208/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2772 - accuracy: 0.8903 - val_loss: 0.2499 - val_accuracy: 0.8959\n",
            "Epoch 209/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2638 - accuracy: 0.8908 - val_loss: 0.2487 - val_accuracy: 0.8945\n",
            "Epoch 210/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2752 - accuracy: 0.8852 - val_loss: 0.2496 - val_accuracy: 0.8945\n",
            "Epoch 211/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2637 - accuracy: 0.8915 - val_loss: 0.2503 - val_accuracy: 0.8886\n",
            "Epoch 212/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2773 - accuracy: 0.8874 - val_loss: 0.2479 - val_accuracy: 0.8951\n",
            "Epoch 213/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2861 - accuracy: 0.8880 - val_loss: 0.2509 - val_accuracy: 0.8948\n",
            "Epoch 214/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2721 - accuracy: 0.8891 - val_loss: 0.2462 - val_accuracy: 0.8942\n",
            "Epoch 215/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2734 - accuracy: 0.8867 - val_loss: 0.2529 - val_accuracy: 0.8968\n",
            "Epoch 216/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2727 - accuracy: 0.8877 - val_loss: 0.2480 - val_accuracy: 0.8939\n",
            "Epoch 217/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2851 - accuracy: 0.8824 - val_loss: 0.2455 - val_accuracy: 0.8889\n",
            "Epoch 218/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2768 - accuracy: 0.8845 - val_loss: 0.2464 - val_accuracy: 0.8889\n",
            "Epoch 219/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2672 - accuracy: 0.8864 - val_loss: 0.2495 - val_accuracy: 0.8945\n",
            "Epoch 220/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2644 - accuracy: 0.8902 - val_loss: 0.2471 - val_accuracy: 0.8891\n",
            "Epoch 221/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2609 - accuracy: 0.8877 - val_loss: 0.2462 - val_accuracy: 0.8906\n",
            "Epoch 222/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2851 - accuracy: 0.8830 - val_loss: 0.2476 - val_accuracy: 0.8886\n",
            "Epoch 223/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2685 - accuracy: 0.8894 - val_loss: 0.2465 - val_accuracy: 0.8874\n",
            "Epoch 224/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2697 - accuracy: 0.8915 - val_loss: 0.2461 - val_accuracy: 0.8948\n",
            "Epoch 225/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2774 - accuracy: 0.8849 - val_loss: 0.2551 - val_accuracy: 0.8956\n",
            "Epoch 226/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2762 - accuracy: 0.8816 - val_loss: 0.2477 - val_accuracy: 0.8908\n",
            "Epoch 227/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2730 - accuracy: 0.8910 - val_loss: 0.2469 - val_accuracy: 0.8917\n",
            "Epoch 228/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2558 - accuracy: 0.8998 - val_loss: 0.2527 - val_accuracy: 0.8945\n",
            "Epoch 229/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2660 - accuracy: 0.8899 - val_loss: 0.2491 - val_accuracy: 0.8917\n",
            "Epoch 230/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2746 - accuracy: 0.8882 - val_loss: 0.2456 - val_accuracy: 0.8889\n",
            "Epoch 231/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2657 - accuracy: 0.8902 - val_loss: 0.2472 - val_accuracy: 0.8948\n",
            "Epoch 232/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2577 - accuracy: 0.8932 - val_loss: 0.2556 - val_accuracy: 0.8931\n",
            "Epoch 233/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2646 - accuracy: 0.8957 - val_loss: 0.2567 - val_accuracy: 0.8951\n",
            "Epoch 234/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2704 - accuracy: 0.8887 - val_loss: 0.2489 - val_accuracy: 0.8945\n",
            "Epoch 235/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2762 - accuracy: 0.8864 - val_loss: 0.2459 - val_accuracy: 0.8917\n",
            "Epoch 236/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2706 - accuracy: 0.8850 - val_loss: 0.2527 - val_accuracy: 0.8948\n",
            "Epoch 237/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2733 - accuracy: 0.8898 - val_loss: 0.2465 - val_accuracy: 0.8939\n",
            "Epoch 238/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2814 - accuracy: 0.8818 - val_loss: 0.2471 - val_accuracy: 0.8908\n",
            "Epoch 239/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2842 - accuracy: 0.8891 - val_loss: 0.2453 - val_accuracy: 0.8894\n",
            "Epoch 240/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2683 - accuracy: 0.8919 - val_loss: 0.2490 - val_accuracy: 0.8945\n",
            "Epoch 241/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2724 - accuracy: 0.8867 - val_loss: 0.2486 - val_accuracy: 0.8965\n",
            "Epoch 242/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2670 - accuracy: 0.8859 - val_loss: 0.2490 - val_accuracy: 0.8953\n",
            "Epoch 243/1000\n",
            "259/259 [==============================] - 1s 4ms/step - loss: 0.2789 - accuracy: 0.8852 - val_loss: 0.2486 - val_accuracy: 0.8945\n",
            "Epoch 244/1000\n",
            "259/259 [==============================] - 1s 4ms/step - loss: 0.2698 - accuracy: 0.8905 - val_loss: 0.2456 - val_accuracy: 0.8959\n",
            "Epoch 245/1000\n",
            "259/259 [==============================] - 1s 4ms/step - loss: 0.2613 - accuracy: 0.8924 - val_loss: 0.2499 - val_accuracy: 0.8928\n",
            "Epoch 246/1000\n",
            "259/259 [==============================] - 1s 4ms/step - loss: 0.2715 - accuracy: 0.8917 - val_loss: 0.2492 - val_accuracy: 0.8925\n",
            "Epoch 247/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2644 - accuracy: 0.8912 - val_loss: 0.2504 - val_accuracy: 0.8959\n",
            "Epoch 248/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2740 - accuracy: 0.8858 - val_loss: 0.2479 - val_accuracy: 0.8925\n",
            "Epoch 249/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2683 - accuracy: 0.8884 - val_loss: 0.2501 - val_accuracy: 0.8942\n",
            "Epoch 250/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2632 - accuracy: 0.8887 - val_loss: 0.2474 - val_accuracy: 0.8945\n",
            "Epoch 251/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2666 - accuracy: 0.8882 - val_loss: 0.2469 - val_accuracy: 0.8917\n",
            "Epoch 252/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2668 - accuracy: 0.8845 - val_loss: 0.2505 - val_accuracy: 0.8937\n",
            "Epoch 253/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2606 - accuracy: 0.8967 - val_loss: 0.2551 - val_accuracy: 0.8939\n",
            "Epoch 254/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2648 - accuracy: 0.8901 - val_loss: 0.2490 - val_accuracy: 0.8956\n",
            "Epoch 255/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2645 - accuracy: 0.8910 - val_loss: 0.2463 - val_accuracy: 0.8908\n",
            "Epoch 256/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2731 - accuracy: 0.8878 - val_loss: 0.2523 - val_accuracy: 0.8965\n",
            "Epoch 257/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2734 - accuracy: 0.8863 - val_loss: 0.2529 - val_accuracy: 0.8956\n",
            "Epoch 258/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2645 - accuracy: 0.8935 - val_loss: 0.2461 - val_accuracy: 0.8937\n",
            "Epoch 259/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2738 - accuracy: 0.8887 - val_loss: 0.2467 - val_accuracy: 0.8948\n",
            "Epoch 260/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2690 - accuracy: 0.8890 - val_loss: 0.2472 - val_accuracy: 0.8942\n",
            "Epoch 261/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2688 - accuracy: 0.8866 - val_loss: 0.2482 - val_accuracy: 0.8900\n",
            "Epoch 262/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2682 - accuracy: 0.8906 - val_loss: 0.2497 - val_accuracy: 0.8934\n",
            "Epoch 263/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2783 - accuracy: 0.8840 - val_loss: 0.2473 - val_accuracy: 0.8894\n",
            "Epoch 264/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2775 - accuracy: 0.8813 - val_loss: 0.2464 - val_accuracy: 0.8877\n",
            "Epoch 265/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2628 - accuracy: 0.8912 - val_loss: 0.2531 - val_accuracy: 0.8948\n",
            "Epoch 266/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2744 - accuracy: 0.8864 - val_loss: 0.2482 - val_accuracy: 0.8951\n",
            "Epoch 267/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2646 - accuracy: 0.8941 - val_loss: 0.2459 - val_accuracy: 0.8970\n",
            "Epoch 268/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2612 - accuracy: 0.8910 - val_loss: 0.2536 - val_accuracy: 0.8953\n",
            "Epoch 269/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2624 - accuracy: 0.8976 - val_loss: 0.2497 - val_accuracy: 0.8917\n",
            "Epoch 270/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2888 - accuracy: 0.8826 - val_loss: 0.2455 - val_accuracy: 0.8922\n",
            "Epoch 271/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2710 - accuracy: 0.8899 - val_loss: 0.2471 - val_accuracy: 0.8903\n",
            "Epoch 272/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2729 - accuracy: 0.8909 - val_loss: 0.2459 - val_accuracy: 0.8948\n",
            "Epoch 273/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2790 - accuracy: 0.8789 - val_loss: 0.2458 - val_accuracy: 0.8897\n",
            "Epoch 274/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2738 - accuracy: 0.8828 - val_loss: 0.2467 - val_accuracy: 0.8920\n",
            "Epoch 275/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2820 - accuracy: 0.8898 - val_loss: 0.2463 - val_accuracy: 0.8914\n",
            "Epoch 276/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2714 - accuracy: 0.8895 - val_loss: 0.2456 - val_accuracy: 0.8939\n",
            "Epoch 277/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2776 - accuracy: 0.8845 - val_loss: 0.2461 - val_accuracy: 0.8939\n",
            "Epoch 278/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2687 - accuracy: 0.8883 - val_loss: 0.2496 - val_accuracy: 0.8920\n",
            "Epoch 279/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2873 - accuracy: 0.8892 - val_loss: 0.2481 - val_accuracy: 0.8965\n",
            "Epoch 280/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2643 - accuracy: 0.8936 - val_loss: 0.2476 - val_accuracy: 0.8956\n",
            "Epoch 281/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2841 - accuracy: 0.8851 - val_loss: 0.2453 - val_accuracy: 0.8886\n",
            "Epoch 282/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2699 - accuracy: 0.8838 - val_loss: 0.2478 - val_accuracy: 0.8953\n",
            "Epoch 283/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2676 - accuracy: 0.8872 - val_loss: 0.2504 - val_accuracy: 0.8956\n",
            "Epoch 284/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2664 - accuracy: 0.8888 - val_loss: 0.2540 - val_accuracy: 0.8951\n",
            "Epoch 285/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2676 - accuracy: 0.8877 - val_loss: 0.2489 - val_accuracy: 0.8925\n",
            "Epoch 286/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2663 - accuracy: 0.8869 - val_loss: 0.2502 - val_accuracy: 0.8953\n",
            "Epoch 287/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2706 - accuracy: 0.8805 - val_loss: 0.2505 - val_accuracy: 0.8917\n",
            "Epoch 288/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2696 - accuracy: 0.8930 - val_loss: 0.2463 - val_accuracy: 0.8934\n",
            "Epoch 289/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2635 - accuracy: 0.8925 - val_loss: 0.2465 - val_accuracy: 0.8911\n",
            "Epoch 290/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2640 - accuracy: 0.8939 - val_loss: 0.2446 - val_accuracy: 0.8903\n",
            "Epoch 291/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2669 - accuracy: 0.8905 - val_loss: 0.2492 - val_accuracy: 0.8942\n",
            "Epoch 292/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2652 - accuracy: 0.8847 - val_loss: 0.2451 - val_accuracy: 0.8931\n",
            "Epoch 293/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2670 - accuracy: 0.8905 - val_loss: 0.2475 - val_accuracy: 0.8937\n",
            "Epoch 294/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2800 - accuracy: 0.8845 - val_loss: 0.2489 - val_accuracy: 0.8939\n",
            "Epoch 295/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2792 - accuracy: 0.8900 - val_loss: 0.2554 - val_accuracy: 0.8931\n",
            "Epoch 296/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2809 - accuracy: 0.8815 - val_loss: 0.2464 - val_accuracy: 0.8945\n",
            "Epoch 1/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2660 - accuracy: 0.8929 - val_loss: 0.2478 - val_accuracy: 0.8925\n",
            "Epoch 2/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2703 - accuracy: 0.8881 - val_loss: 0.2549 - val_accuracy: 0.8965\n",
            "Epoch 3/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2690 - accuracy: 0.8873 - val_loss: 0.2484 - val_accuracy: 0.8925\n",
            "Epoch 4/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2735 - accuracy: 0.8894 - val_loss: 0.2471 - val_accuracy: 0.8897\n",
            "Epoch 5/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2843 - accuracy: 0.8784 - val_loss: 0.2467 - val_accuracy: 0.8920\n",
            "Epoch 6/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2698 - accuracy: 0.8956 - val_loss: 0.2510 - val_accuracy: 0.8953\n",
            "Epoch 7/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2706 - accuracy: 0.8881 - val_loss: 0.2485 - val_accuracy: 0.8880\n",
            "Epoch 8/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2716 - accuracy: 0.8894 - val_loss: 0.2481 - val_accuracy: 0.8925\n",
            "Epoch 9/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2715 - accuracy: 0.8854 - val_loss: 0.2484 - val_accuracy: 0.8934\n",
            "Epoch 10/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2680 - accuracy: 0.8862 - val_loss: 0.2495 - val_accuracy: 0.8942\n",
            "Epoch 11/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2600 - accuracy: 0.8921 - val_loss: 0.2479 - val_accuracy: 0.8925\n",
            "Epoch 12/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2694 - accuracy: 0.8846 - val_loss: 0.2483 - val_accuracy: 0.8849\n",
            "Epoch 13/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2609 - accuracy: 0.8951 - val_loss: 0.2541 - val_accuracy: 0.8942\n",
            "Epoch 14/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2609 - accuracy: 0.8960 - val_loss: 0.2515 - val_accuracy: 0.8945\n",
            "Epoch 15/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2684 - accuracy: 0.8906 - val_loss: 0.2498 - val_accuracy: 0.8894\n",
            "Epoch 16/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2755 - accuracy: 0.8907 - val_loss: 0.2524 - val_accuracy: 0.8945\n",
            "Epoch 17/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2858 - accuracy: 0.8818 - val_loss: 0.2491 - val_accuracy: 0.8886\n",
            "Epoch 18/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2758 - accuracy: 0.8847 - val_loss: 0.2478 - val_accuracy: 0.8889\n",
            "Epoch 19/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2689 - accuracy: 0.8931 - val_loss: 0.2481 - val_accuracy: 0.8858\n",
            "Epoch 20/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2709 - accuracy: 0.8883 - val_loss: 0.2478 - val_accuracy: 0.8945\n",
            "Epoch 21/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2563 - accuracy: 0.8950 - val_loss: 0.2485 - val_accuracy: 0.8891\n",
            "Epoch 22/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2669 - accuracy: 0.8885 - val_loss: 0.2476 - val_accuracy: 0.8917\n",
            "Epoch 23/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2739 - accuracy: 0.8860 - val_loss: 0.2456 - val_accuracy: 0.8903\n",
            "Epoch 24/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2819 - accuracy: 0.8884 - val_loss: 0.2508 - val_accuracy: 0.8900\n",
            "Epoch 25/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2784 - accuracy: 0.8866 - val_loss: 0.2502 - val_accuracy: 0.8953\n",
            "Epoch 26/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2834 - accuracy: 0.8801 - val_loss: 0.2510 - val_accuracy: 0.8973\n",
            "Epoch 27/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2671 - accuracy: 0.8906 - val_loss: 0.2457 - val_accuracy: 0.8948\n",
            "Epoch 28/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2804 - accuracy: 0.8852 - val_loss: 0.2504 - val_accuracy: 0.8937\n",
            "Epoch 29/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2799 - accuracy: 0.8841 - val_loss: 0.2477 - val_accuracy: 0.8939\n",
            "Epoch 30/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2633 - accuracy: 0.8912 - val_loss: 0.2507 - val_accuracy: 0.8948\n",
            "Epoch 31/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2734 - accuracy: 0.8891 - val_loss: 0.2466 - val_accuracy: 0.8906\n",
            "Epoch 32/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2654 - accuracy: 0.8926 - val_loss: 0.2467 - val_accuracy: 0.8917\n",
            "Epoch 33/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2630 - accuracy: 0.8993 - val_loss: 0.2485 - val_accuracy: 0.8920\n",
            "Epoch 34/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2717 - accuracy: 0.8881 - val_loss: 0.2486 - val_accuracy: 0.8897\n",
            "Epoch 35/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2613 - accuracy: 0.8931 - val_loss: 0.2506 - val_accuracy: 0.8931\n",
            "Epoch 36/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2595 - accuracy: 0.8951 - val_loss: 0.2511 - val_accuracy: 0.8934\n",
            "Epoch 37/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2710 - accuracy: 0.8884 - val_loss: 0.2561 - val_accuracy: 0.8939\n",
            "Epoch 38/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2664 - accuracy: 0.8900 - val_loss: 0.2513 - val_accuracy: 0.8937\n",
            "Epoch 39/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2783 - accuracy: 0.8891 - val_loss: 0.2659 - val_accuracy: 0.8968\n",
            "Epoch 40/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2667 - accuracy: 0.8926 - val_loss: 0.2453 - val_accuracy: 0.8953\n",
            "Epoch 41/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2746 - accuracy: 0.8890 - val_loss: 0.2448 - val_accuracy: 0.8906\n",
            "Epoch 42/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2687 - accuracy: 0.8893 - val_loss: 0.2470 - val_accuracy: 0.8942\n",
            "Epoch 43/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2553 - accuracy: 0.9009 - val_loss: 0.2552 - val_accuracy: 0.8931\n",
            "Epoch 44/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2725 - accuracy: 0.8931 - val_loss: 0.2543 - val_accuracy: 0.8965\n",
            "Epoch 45/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2615 - accuracy: 0.8930 - val_loss: 0.2475 - val_accuracy: 0.8925\n",
            "Epoch 46/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2713 - accuracy: 0.8909 - val_loss: 0.2463 - val_accuracy: 0.8937\n",
            "Epoch 47/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2676 - accuracy: 0.8911 - val_loss: 0.2483 - val_accuracy: 0.8937\n",
            "Epoch 48/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2724 - accuracy: 0.8885 - val_loss: 0.2544 - val_accuracy: 0.8934\n",
            "Epoch 49/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2733 - accuracy: 0.8858 - val_loss: 0.2467 - val_accuracy: 0.8962\n",
            "Epoch 50/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2654 - accuracy: 0.8941 - val_loss: 0.2501 - val_accuracy: 0.8965\n",
            "Epoch 51/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2768 - accuracy: 0.8874 - val_loss: 0.2501 - val_accuracy: 0.8945\n",
            "Epoch 52/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2759 - accuracy: 0.8860 - val_loss: 0.2497 - val_accuracy: 0.8948\n",
            "Epoch 53/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2710 - accuracy: 0.8902 - val_loss: 0.2467 - val_accuracy: 0.8948\n",
            "Epoch 54/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2615 - accuracy: 0.8916 - val_loss: 0.2565 - val_accuracy: 0.8953\n",
            "Epoch 55/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2723 - accuracy: 0.8870 - val_loss: 0.2534 - val_accuracy: 0.8931\n",
            "Epoch 56/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2590 - accuracy: 0.8891 - val_loss: 0.2470 - val_accuracy: 0.8948\n",
            "Epoch 57/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2558 - accuracy: 0.8978 - val_loss: 0.2462 - val_accuracy: 0.8928\n",
            "Epoch 58/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2646 - accuracy: 0.8888 - val_loss: 0.2461 - val_accuracy: 0.8889\n",
            "Epoch 59/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2632 - accuracy: 0.8919 - val_loss: 0.2485 - val_accuracy: 0.8911\n",
            "Epoch 60/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2778 - accuracy: 0.8856 - val_loss: 0.2490 - val_accuracy: 0.8937\n",
            "Epoch 61/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2652 - accuracy: 0.8935 - val_loss: 0.2496 - val_accuracy: 0.8942\n",
            "Epoch 62/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2634 - accuracy: 0.8902 - val_loss: 0.2455 - val_accuracy: 0.8894\n",
            "Epoch 63/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2787 - accuracy: 0.8807 - val_loss: 0.2473 - val_accuracy: 0.8894\n",
            "Epoch 64/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2732 - accuracy: 0.8883 - val_loss: 0.2457 - val_accuracy: 0.8908\n",
            "Epoch 65/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2638 - accuracy: 0.8927 - val_loss: 0.2513 - val_accuracy: 0.8942\n",
            "Epoch 66/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2697 - accuracy: 0.8898 - val_loss: 0.2460 - val_accuracy: 0.8953\n",
            "Epoch 67/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2722 - accuracy: 0.8832 - val_loss: 0.2471 - val_accuracy: 0.8948\n",
            "Epoch 68/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2670 - accuracy: 0.8879 - val_loss: 0.2505 - val_accuracy: 0.8962\n",
            "Epoch 69/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2680 - accuracy: 0.8900 - val_loss: 0.2485 - val_accuracy: 0.8920\n",
            "Epoch 70/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2658 - accuracy: 0.8912 - val_loss: 0.2460 - val_accuracy: 0.8942\n",
            "Epoch 71/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2637 - accuracy: 0.8907 - val_loss: 0.2503 - val_accuracy: 0.8934\n",
            "Epoch 72/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2693 - accuracy: 0.8911 - val_loss: 0.2463 - val_accuracy: 0.8973\n",
            "Epoch 73/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2568 - accuracy: 0.8952 - val_loss: 0.2452 - val_accuracy: 0.8959\n",
            "Epoch 74/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2758 - accuracy: 0.8855 - val_loss: 0.2478 - val_accuracy: 0.8953\n",
            "Epoch 75/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2710 - accuracy: 0.8860 - val_loss: 0.2458 - val_accuracy: 0.8920\n",
            "Epoch 76/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2657 - accuracy: 0.8911 - val_loss: 0.2470 - val_accuracy: 0.8937\n",
            "Epoch 77/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2708 - accuracy: 0.8863 - val_loss: 0.2469 - val_accuracy: 0.8945\n",
            "Epoch 78/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2652 - accuracy: 0.8920 - val_loss: 0.2484 - val_accuracy: 0.8928\n",
            "Epoch 79/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2782 - accuracy: 0.8856 - val_loss: 0.2468 - val_accuracy: 0.8956\n",
            "Epoch 80/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2572 - accuracy: 0.8962 - val_loss: 0.2473 - val_accuracy: 0.8953\n",
            "Epoch 81/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2683 - accuracy: 0.8892 - val_loss: 0.2532 - val_accuracy: 0.8937\n",
            "Epoch 82/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2651 - accuracy: 0.8888 - val_loss: 0.2543 - val_accuracy: 0.8942\n",
            "Epoch 83/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2759 - accuracy: 0.8864 - val_loss: 0.2501 - val_accuracy: 0.8951\n",
            "Epoch 84/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2751 - accuracy: 0.8873 - val_loss: 0.2446 - val_accuracy: 0.8900\n",
            "Epoch 85/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2660 - accuracy: 0.8958 - val_loss: 0.2499 - val_accuracy: 0.8959\n",
            "Epoch 86/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2770 - accuracy: 0.8862 - val_loss: 0.2473 - val_accuracy: 0.8951\n",
            "Epoch 87/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2643 - accuracy: 0.8912 - val_loss: 0.2461 - val_accuracy: 0.8951\n",
            "Epoch 88/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2638 - accuracy: 0.8905 - val_loss: 0.2473 - val_accuracy: 0.8948\n",
            "Epoch 89/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2663 - accuracy: 0.8893 - val_loss: 0.2506 - val_accuracy: 0.8951\n",
            "Epoch 90/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2699 - accuracy: 0.8889 - val_loss: 0.2473 - val_accuracy: 0.8908\n",
            "Epoch 91/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2747 - accuracy: 0.8911 - val_loss: 0.2527 - val_accuracy: 0.8973\n",
            "Epoch 92/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2634 - accuracy: 0.8930 - val_loss: 0.2472 - val_accuracy: 0.8942\n",
            "Epoch 93/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2706 - accuracy: 0.8875 - val_loss: 0.2450 - val_accuracy: 0.8934\n",
            "Epoch 94/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2666 - accuracy: 0.8885 - val_loss: 0.2462 - val_accuracy: 0.8917\n",
            "Epoch 95/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2624 - accuracy: 0.8959 - val_loss: 0.2530 - val_accuracy: 0.8937\n",
            "Epoch 96/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2679 - accuracy: 0.8894 - val_loss: 0.2612 - val_accuracy: 0.8948\n",
            "Epoch 97/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2765 - accuracy: 0.8877 - val_loss: 0.2453 - val_accuracy: 0.8886\n",
            "Epoch 98/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2581 - accuracy: 0.8956 - val_loss: 0.2469 - val_accuracy: 0.8922\n",
            "Epoch 99/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2639 - accuracy: 0.8874 - val_loss: 0.2450 - val_accuracy: 0.8928\n",
            "Epoch 100/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2766 - accuracy: 0.8852 - val_loss: 0.2450 - val_accuracy: 0.8937\n",
            "Epoch 101/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2762 - accuracy: 0.8867 - val_loss: 0.2455 - val_accuracy: 0.8928\n",
            "Epoch 102/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2691 - accuracy: 0.8883 - val_loss: 0.2459 - val_accuracy: 0.8939\n",
            "Epoch 103/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2746 - accuracy: 0.8865 - val_loss: 0.2448 - val_accuracy: 0.8900\n",
            "Epoch 104/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2770 - accuracy: 0.8856 - val_loss: 0.2459 - val_accuracy: 0.8951\n",
            "Epoch 105/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2701 - accuracy: 0.8898 - val_loss: 0.2452 - val_accuracy: 0.8903\n",
            "Epoch 106/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2737 - accuracy: 0.8847 - val_loss: 0.2530 - val_accuracy: 0.8965\n",
            "Epoch 107/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2607 - accuracy: 0.8942 - val_loss: 0.2451 - val_accuracy: 0.8866\n",
            "Epoch 108/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2693 - accuracy: 0.8889 - val_loss: 0.2456 - val_accuracy: 0.8914\n",
            "Epoch 109/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2641 - accuracy: 0.8957 - val_loss: 0.2570 - val_accuracy: 0.8948\n",
            "Epoch 110/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2743 - accuracy: 0.8878 - val_loss: 0.2485 - val_accuracy: 0.8939\n",
            "Epoch 111/1000\n",
            "259/259 [==============================] - 1s 2ms/step - loss: 0.2764 - accuracy: 0.8876 - val_loss: 0.2482 - val_accuracy: 0.8942\n",
            "Epoch 112/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2627 - accuracy: 0.8921 - val_loss: 0.2446 - val_accuracy: 0.8920\n",
            "Epoch 113/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2715 - accuracy: 0.8860 - val_loss: 0.2499 - val_accuracy: 0.8951\n",
            "Epoch 114/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2685 - accuracy: 0.8893 - val_loss: 0.2472 - val_accuracy: 0.8945\n",
            "Epoch 115/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2784 - accuracy: 0.8865 - val_loss: 0.2458 - val_accuracy: 0.8883\n",
            "Epoch 116/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2653 - accuracy: 0.8891 - val_loss: 0.2513 - val_accuracy: 0.8934\n",
            "Epoch 117/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2764 - accuracy: 0.8895 - val_loss: 0.2480 - val_accuracy: 0.8970\n",
            "Epoch 118/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2648 - accuracy: 0.8894 - val_loss: 0.2488 - val_accuracy: 0.8948\n",
            "Epoch 119/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2790 - accuracy: 0.8815 - val_loss: 0.2479 - val_accuracy: 0.8937\n",
            "Epoch 120/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2837 - accuracy: 0.8834 - val_loss: 0.2481 - val_accuracy: 0.8880\n",
            "Epoch 121/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2743 - accuracy: 0.8862 - val_loss: 0.2489 - val_accuracy: 0.8934\n",
            "Epoch 122/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2664 - accuracy: 0.8901 - val_loss: 0.2440 - val_accuracy: 0.8920\n",
            "Epoch 123/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2581 - accuracy: 0.8933 - val_loss: 0.2517 - val_accuracy: 0.8984\n",
            "Epoch 124/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2818 - accuracy: 0.8846 - val_loss: 0.2456 - val_accuracy: 0.8942\n",
            "Epoch 125/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2755 - accuracy: 0.8811 - val_loss: 0.2465 - val_accuracy: 0.8883\n",
            "Epoch 126/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2747 - accuracy: 0.8886 - val_loss: 0.2436 - val_accuracy: 0.8948\n",
            "Epoch 127/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2633 - accuracy: 0.8890 - val_loss: 0.2492 - val_accuracy: 0.8939\n",
            "Epoch 128/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2625 - accuracy: 0.8937 - val_loss: 0.2445 - val_accuracy: 0.8965\n",
            "Epoch 129/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2756 - accuracy: 0.8893 - val_loss: 0.2465 - val_accuracy: 0.8945\n",
            "Epoch 130/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2687 - accuracy: 0.8893 - val_loss: 0.2502 - val_accuracy: 0.8956\n",
            "Epoch 131/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2766 - accuracy: 0.8902 - val_loss: 0.2493 - val_accuracy: 0.8948\n",
            "Epoch 132/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2743 - accuracy: 0.8901 - val_loss: 0.2460 - val_accuracy: 0.8937\n",
            "Epoch 133/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2648 - accuracy: 0.8915 - val_loss: 0.2484 - val_accuracy: 0.8970\n",
            "Epoch 134/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2648 - accuracy: 0.8923 - val_loss: 0.2506 - val_accuracy: 0.8973\n",
            "Epoch 135/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2610 - accuracy: 0.8925 - val_loss: 0.2497 - val_accuracy: 0.8917\n",
            "Epoch 136/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2800 - accuracy: 0.8903 - val_loss: 0.2471 - val_accuracy: 0.8931\n",
            "Epoch 137/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2730 - accuracy: 0.8878 - val_loss: 0.2510 - val_accuracy: 0.8948\n",
            "Epoch 138/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2614 - accuracy: 0.8918 - val_loss: 0.2445 - val_accuracy: 0.8953\n",
            "Epoch 139/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2672 - accuracy: 0.8867 - val_loss: 0.2476 - val_accuracy: 0.8908\n",
            "Epoch 140/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2657 - accuracy: 0.8890 - val_loss: 0.2476 - val_accuracy: 0.8956\n",
            "Epoch 141/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2657 - accuracy: 0.8888 - val_loss: 0.2455 - val_accuracy: 0.8920\n",
            "Epoch 142/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2702 - accuracy: 0.8899 - val_loss: 0.2530 - val_accuracy: 0.8968\n",
            "Epoch 143/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2660 - accuracy: 0.8886 - val_loss: 0.2491 - val_accuracy: 0.8939\n",
            "Epoch 144/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2648 - accuracy: 0.8907 - val_loss: 0.2463 - val_accuracy: 0.8914\n",
            "Epoch 145/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2756 - accuracy: 0.8890 - val_loss: 0.2511 - val_accuracy: 0.8959\n",
            "Epoch 146/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2680 - accuracy: 0.8921 - val_loss: 0.2446 - val_accuracy: 0.8908\n",
            "Epoch 147/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2673 - accuracy: 0.8915 - val_loss: 0.2481 - val_accuracy: 0.8894\n",
            "Epoch 148/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2648 - accuracy: 0.8888 - val_loss: 0.2498 - val_accuracy: 0.8956\n",
            "Epoch 149/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2588 - accuracy: 0.8973 - val_loss: 0.2435 - val_accuracy: 0.8928\n",
            "Epoch 150/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2649 - accuracy: 0.8885 - val_loss: 0.2529 - val_accuracy: 0.8968\n",
            "Epoch 151/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2686 - accuracy: 0.8871 - val_loss: 0.2457 - val_accuracy: 0.8956\n",
            "Epoch 152/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2655 - accuracy: 0.8924 - val_loss: 0.2468 - val_accuracy: 0.8945\n",
            "Epoch 153/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2689 - accuracy: 0.8898 - val_loss: 0.2457 - val_accuracy: 0.8956\n",
            "Epoch 154/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2707 - accuracy: 0.8902 - val_loss: 0.2463 - val_accuracy: 0.8934\n",
            "Epoch 155/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2749 - accuracy: 0.8870 - val_loss: 0.2530 - val_accuracy: 0.8948\n",
            "Epoch 156/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2658 - accuracy: 0.8937 - val_loss: 0.2455 - val_accuracy: 0.8953\n",
            "Epoch 157/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2630 - accuracy: 0.8955 - val_loss: 0.2450 - val_accuracy: 0.8970\n",
            "Epoch 158/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2661 - accuracy: 0.8893 - val_loss: 0.2509 - val_accuracy: 0.8956\n",
            "Epoch 159/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2834 - accuracy: 0.8840 - val_loss: 0.2472 - val_accuracy: 0.8894\n",
            "Epoch 160/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2707 - accuracy: 0.8861 - val_loss: 0.2439 - val_accuracy: 0.8965\n",
            "Epoch 161/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2694 - accuracy: 0.8886 - val_loss: 0.2438 - val_accuracy: 0.8914\n",
            "Epoch 162/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2804 - accuracy: 0.8810 - val_loss: 0.2454 - val_accuracy: 0.8894\n",
            "Epoch 163/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2670 - accuracy: 0.8885 - val_loss: 0.2450 - val_accuracy: 0.8894\n",
            "Epoch 164/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2695 - accuracy: 0.8890 - val_loss: 0.2504 - val_accuracy: 0.8956\n",
            "Epoch 165/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2681 - accuracy: 0.8914 - val_loss: 0.2446 - val_accuracy: 0.8934\n",
            "Epoch 166/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2617 - accuracy: 0.8903 - val_loss: 0.2471 - val_accuracy: 0.8928\n",
            "Epoch 167/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2651 - accuracy: 0.8880 - val_loss: 0.2450 - val_accuracy: 0.8917\n",
            "Epoch 168/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2663 - accuracy: 0.8869 - val_loss: 0.2479 - val_accuracy: 0.8948\n",
            "Epoch 169/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2644 - accuracy: 0.8967 - val_loss: 0.2467 - val_accuracy: 0.8908\n",
            "Epoch 170/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2595 - accuracy: 0.8904 - val_loss: 0.2479 - val_accuracy: 0.8934\n",
            "Epoch 171/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2761 - accuracy: 0.8845 - val_loss: 0.2440 - val_accuracy: 0.8889\n",
            "Epoch 172/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2780 - accuracy: 0.8892 - val_loss: 0.2451 - val_accuracy: 0.8942\n",
            "Epoch 173/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2754 - accuracy: 0.8861 - val_loss: 0.2592 - val_accuracy: 0.8953\n",
            "Epoch 174/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2673 - accuracy: 0.8938 - val_loss: 0.2467 - val_accuracy: 0.8939\n",
            "Epoch 175/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2645 - accuracy: 0.8908 - val_loss: 0.2457 - val_accuracy: 0.8900\n",
            "Epoch 176/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2748 - accuracy: 0.8844 - val_loss: 0.2435 - val_accuracy: 0.8925\n",
            "Epoch 177/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2562 - accuracy: 0.8979 - val_loss: 0.2486 - val_accuracy: 0.8942\n",
            "Epoch 178/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2683 - accuracy: 0.8920 - val_loss: 0.2482 - val_accuracy: 0.8973\n",
            "Epoch 179/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2563 - accuracy: 0.9005 - val_loss: 0.2542 - val_accuracy: 0.8948\n",
            "Epoch 180/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2773 - accuracy: 0.8853 - val_loss: 0.2467 - val_accuracy: 0.8914\n",
            "Epoch 181/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2711 - accuracy: 0.8878 - val_loss: 0.2432 - val_accuracy: 0.8906\n",
            "Epoch 182/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2788 - accuracy: 0.8858 - val_loss: 0.2552 - val_accuracy: 0.8982\n",
            "Epoch 183/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2675 - accuracy: 0.8901 - val_loss: 0.2489 - val_accuracy: 0.8945\n",
            "Epoch 184/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2605 - accuracy: 0.8952 - val_loss: 0.2427 - val_accuracy: 0.8934\n",
            "Epoch 185/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2701 - accuracy: 0.8835 - val_loss: 0.2439 - val_accuracy: 0.8942\n",
            "Epoch 1/1000\n",
            "259/259 [==============================] - 2s 4ms/step - loss: 0.2756 - accuracy: 0.8888 - val_loss: 0.2466 - val_accuracy: 0.8897\n",
            "Epoch 2/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2623 - accuracy: 0.8953 - val_loss: 0.2458 - val_accuracy: 0.8928\n",
            "Epoch 3/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2642 - accuracy: 0.8895 - val_loss: 0.2474 - val_accuracy: 0.8934\n",
            "Epoch 4/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2669 - accuracy: 0.8922 - val_loss: 0.2514 - val_accuracy: 0.8956\n",
            "Epoch 5/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2698 - accuracy: 0.8945 - val_loss: 0.2493 - val_accuracy: 0.8959\n",
            "Epoch 6/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2659 - accuracy: 0.8909 - val_loss: 0.2515 - val_accuracy: 0.8973\n",
            "Epoch 7/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2662 - accuracy: 0.8924 - val_loss: 0.2509 - val_accuracy: 0.8942\n",
            "Epoch 8/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2634 - accuracy: 0.8929 - val_loss: 0.2470 - val_accuracy: 0.8917\n",
            "Epoch 9/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2729 - accuracy: 0.8853 - val_loss: 0.2449 - val_accuracy: 0.8914\n",
            "Epoch 10/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2754 - accuracy: 0.8854 - val_loss: 0.2539 - val_accuracy: 0.8931\n",
            "Epoch 11/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2792 - accuracy: 0.8864 - val_loss: 0.2444 - val_accuracy: 0.8908\n",
            "Epoch 12/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2618 - accuracy: 0.8908 - val_loss: 0.2449 - val_accuracy: 0.8968\n",
            "Epoch 13/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2721 - accuracy: 0.8877 - val_loss: 0.2481 - val_accuracy: 0.8903\n",
            "Epoch 14/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2692 - accuracy: 0.8899 - val_loss: 0.2453 - val_accuracy: 0.8917\n",
            "Epoch 15/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2630 - accuracy: 0.8906 - val_loss: 0.2513 - val_accuracy: 0.8965\n",
            "Epoch 16/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2580 - accuracy: 0.8944 - val_loss: 0.2537 - val_accuracy: 0.8953\n",
            "Epoch 17/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2619 - accuracy: 0.8926 - val_loss: 0.2454 - val_accuracy: 0.8911\n",
            "Epoch 18/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2615 - accuracy: 0.8911 - val_loss: 0.2453 - val_accuracy: 0.8922\n",
            "Epoch 19/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2623 - accuracy: 0.8891 - val_loss: 0.2480 - val_accuracy: 0.8951\n",
            "Epoch 20/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2760 - accuracy: 0.8890 - val_loss: 0.2439 - val_accuracy: 0.8959\n",
            "Epoch 21/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2743 - accuracy: 0.8886 - val_loss: 0.2479 - val_accuracy: 0.8959\n",
            "Epoch 22/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2781 - accuracy: 0.8877 - val_loss: 0.2527 - val_accuracy: 0.8925\n",
            "Epoch 23/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2790 - accuracy: 0.8859 - val_loss: 0.2544 - val_accuracy: 0.8951\n",
            "Epoch 24/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2637 - accuracy: 0.8959 - val_loss: 0.2462 - val_accuracy: 0.8934\n",
            "Epoch 25/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2660 - accuracy: 0.8899 - val_loss: 0.2456 - val_accuracy: 0.8922\n",
            "Epoch 26/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2733 - accuracy: 0.8914 - val_loss: 0.2460 - val_accuracy: 0.8959\n",
            "Epoch 27/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2688 - accuracy: 0.8849 - val_loss: 0.2470 - val_accuracy: 0.8900\n",
            "Epoch 28/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2776 - accuracy: 0.8877 - val_loss: 0.2453 - val_accuracy: 0.8956\n",
            "Epoch 29/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2766 - accuracy: 0.8852 - val_loss: 0.2496 - val_accuracy: 0.8968\n",
            "Epoch 30/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2602 - accuracy: 0.8925 - val_loss: 0.2457 - val_accuracy: 0.8911\n",
            "Epoch 31/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2617 - accuracy: 0.8954 - val_loss: 0.2493 - val_accuracy: 0.8970\n",
            "Epoch 32/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2662 - accuracy: 0.8914 - val_loss: 0.2472 - val_accuracy: 0.8953\n",
            "Epoch 33/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2741 - accuracy: 0.8854 - val_loss: 0.2490 - val_accuracy: 0.8973\n",
            "Epoch 34/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2797 - accuracy: 0.8802 - val_loss: 0.2476 - val_accuracy: 0.8942\n",
            "Epoch 35/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2665 - accuracy: 0.8921 - val_loss: 0.2449 - val_accuracy: 0.8877\n",
            "Epoch 36/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2785 - accuracy: 0.8870 - val_loss: 0.2479 - val_accuracy: 0.8939\n",
            "Epoch 37/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2669 - accuracy: 0.8877 - val_loss: 0.2445 - val_accuracy: 0.8942\n",
            "Epoch 38/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2714 - accuracy: 0.8895 - val_loss: 0.2435 - val_accuracy: 0.8934\n",
            "Epoch 39/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2718 - accuracy: 0.8896 - val_loss: 0.2489 - val_accuracy: 0.8951\n",
            "Epoch 40/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2594 - accuracy: 0.8931 - val_loss: 0.2448 - val_accuracy: 0.8962\n",
            "Epoch 41/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2674 - accuracy: 0.8858 - val_loss: 0.2461 - val_accuracy: 0.8928\n",
            "Epoch 42/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2728 - accuracy: 0.8871 - val_loss: 0.2479 - val_accuracy: 0.8931\n",
            "Epoch 43/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2886 - accuracy: 0.8802 - val_loss: 0.2460 - val_accuracy: 0.8953\n",
            "Epoch 44/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2695 - accuracy: 0.8876 - val_loss: 0.2480 - val_accuracy: 0.8956\n",
            "Epoch 45/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2631 - accuracy: 0.8913 - val_loss: 0.2495 - val_accuracy: 0.8945\n",
            "Epoch 46/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2731 - accuracy: 0.8901 - val_loss: 0.2467 - val_accuracy: 0.8956\n",
            "Epoch 47/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2762 - accuracy: 0.8856 - val_loss: 0.2462 - val_accuracy: 0.8956\n",
            "Epoch 48/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2681 - accuracy: 0.8890 - val_loss: 0.2535 - val_accuracy: 0.8962\n",
            "Epoch 49/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2665 - accuracy: 0.8914 - val_loss: 0.2461 - val_accuracy: 0.8953\n",
            "Epoch 50/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2709 - accuracy: 0.8854 - val_loss: 0.2457 - val_accuracy: 0.8945\n",
            "Epoch 51/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2649 - accuracy: 0.8924 - val_loss: 0.2447 - val_accuracy: 0.8903\n",
            "Epoch 52/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2850 - accuracy: 0.8895 - val_loss: 0.2451 - val_accuracy: 0.8914\n",
            "Epoch 53/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2697 - accuracy: 0.8869 - val_loss: 0.2470 - val_accuracy: 0.8942\n",
            "Epoch 54/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2635 - accuracy: 0.8951 - val_loss: 0.2452 - val_accuracy: 0.8951\n",
            "Epoch 55/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2770 - accuracy: 0.8854 - val_loss: 0.2468 - val_accuracy: 0.8953\n",
            "Epoch 56/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2734 - accuracy: 0.8882 - val_loss: 0.2450 - val_accuracy: 0.8951\n",
            "Epoch 57/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2730 - accuracy: 0.8891 - val_loss: 0.2532 - val_accuracy: 0.8973\n",
            "Epoch 58/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2790 - accuracy: 0.8842 - val_loss: 0.2441 - val_accuracy: 0.8922\n",
            "Epoch 59/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2575 - accuracy: 0.8902 - val_loss: 0.2450 - val_accuracy: 0.8917\n",
            "Epoch 60/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2641 - accuracy: 0.8952 - val_loss: 0.2501 - val_accuracy: 0.8959\n",
            "Epoch 61/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2599 - accuracy: 0.8905 - val_loss: 0.2487 - val_accuracy: 0.8953\n",
            "Epoch 62/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2561 - accuracy: 0.8891 - val_loss: 0.2449 - val_accuracy: 0.8945\n",
            "Epoch 63/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2623 - accuracy: 0.8899 - val_loss: 0.2473 - val_accuracy: 0.8951\n",
            "Epoch 64/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2608 - accuracy: 0.8910 - val_loss: 0.2453 - val_accuracy: 0.8942\n",
            "Epoch 65/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2665 - accuracy: 0.8905 - val_loss: 0.2611 - val_accuracy: 0.8987\n",
            "Epoch 66/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2672 - accuracy: 0.8882 - val_loss: 0.2470 - val_accuracy: 0.8937\n",
            "Epoch 67/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2747 - accuracy: 0.8898 - val_loss: 0.2470 - val_accuracy: 0.8956\n",
            "Epoch 68/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2752 - accuracy: 0.8848 - val_loss: 0.2447 - val_accuracy: 0.8959\n",
            "Epoch 69/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2678 - accuracy: 0.8933 - val_loss: 0.2562 - val_accuracy: 0.8956\n",
            "Epoch 70/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2648 - accuracy: 0.8943 - val_loss: 0.2463 - val_accuracy: 0.8962\n",
            "Epoch 71/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2642 - accuracy: 0.8926 - val_loss: 0.2468 - val_accuracy: 0.8942\n",
            "Epoch 72/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2656 - accuracy: 0.8931 - val_loss: 0.2453 - val_accuracy: 0.8908\n",
            "Epoch 73/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2649 - accuracy: 0.8892 - val_loss: 0.2458 - val_accuracy: 0.8931\n",
            "Epoch 74/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2764 - accuracy: 0.8898 - val_loss: 0.2454 - val_accuracy: 0.8928\n",
            "Epoch 75/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2768 - accuracy: 0.8856 - val_loss: 0.2499 - val_accuracy: 0.8962\n",
            "Epoch 76/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2726 - accuracy: 0.8871 - val_loss: 0.2447 - val_accuracy: 0.8953\n",
            "Epoch 77/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2679 - accuracy: 0.8892 - val_loss: 0.2439 - val_accuracy: 0.8942\n",
            "Epoch 78/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2789 - accuracy: 0.8845 - val_loss: 0.2435 - val_accuracy: 0.8920\n",
            "Epoch 79/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2623 - accuracy: 0.8956 - val_loss: 0.2453 - val_accuracy: 0.8920\n",
            "Epoch 80/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2637 - accuracy: 0.8918 - val_loss: 0.2473 - val_accuracy: 0.8942\n",
            "Epoch 81/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2551 - accuracy: 0.8972 - val_loss: 0.2461 - val_accuracy: 0.8917\n",
            "Epoch 82/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2713 - accuracy: 0.8899 - val_loss: 0.2433 - val_accuracy: 0.8937\n",
            "Epoch 83/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2608 - accuracy: 0.8910 - val_loss: 0.2457 - val_accuracy: 0.8939\n",
            "Epoch 84/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2624 - accuracy: 0.8865 - val_loss: 0.2452 - val_accuracy: 0.8968\n",
            "Epoch 85/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2643 - accuracy: 0.8952 - val_loss: 0.2470 - val_accuracy: 0.8922\n",
            "Epoch 86/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2702 - accuracy: 0.8902 - val_loss: 0.2445 - val_accuracy: 0.8934\n",
            "Epoch 87/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2675 - accuracy: 0.8846 - val_loss: 0.2493 - val_accuracy: 0.8962\n",
            "Epoch 88/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2714 - accuracy: 0.8923 - val_loss: 0.2448 - val_accuracy: 0.8962\n",
            "Epoch 89/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2677 - accuracy: 0.8863 - val_loss: 0.2524 - val_accuracy: 0.8951\n",
            "Epoch 90/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2694 - accuracy: 0.8930 - val_loss: 0.2443 - val_accuracy: 0.8908\n",
            "Epoch 91/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2738 - accuracy: 0.8886 - val_loss: 0.2522 - val_accuracy: 0.8934\n",
            "Epoch 92/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2712 - accuracy: 0.8872 - val_loss: 0.2497 - val_accuracy: 0.8965\n",
            "Epoch 93/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2793 - accuracy: 0.8838 - val_loss: 0.2511 - val_accuracy: 0.8959\n",
            "Epoch 94/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2681 - accuracy: 0.8918 - val_loss: 0.2446 - val_accuracy: 0.8920\n",
            "Epoch 95/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2652 - accuracy: 0.8969 - val_loss: 0.2489 - val_accuracy: 0.8948\n",
            "Epoch 96/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2676 - accuracy: 0.8945 - val_loss: 0.2434 - val_accuracy: 0.8948\n",
            "Epoch 97/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2696 - accuracy: 0.8892 - val_loss: 0.2451 - val_accuracy: 0.8979\n",
            "Epoch 98/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2790 - accuracy: 0.8880 - val_loss: 0.2432 - val_accuracy: 0.8976\n",
            "Epoch 99/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2660 - accuracy: 0.8926 - val_loss: 0.2465 - val_accuracy: 0.8970\n",
            "Epoch 100/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2738 - accuracy: 0.8877 - val_loss: 0.2455 - val_accuracy: 0.8953\n",
            "Epoch 101/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2652 - accuracy: 0.8875 - val_loss: 0.2430 - val_accuracy: 0.8962\n",
            "Epoch 102/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2669 - accuracy: 0.8968 - val_loss: 0.2474 - val_accuracy: 0.8962\n",
            "Epoch 103/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2726 - accuracy: 0.8944 - val_loss: 0.2454 - val_accuracy: 0.8965\n",
            "Epoch 104/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2655 - accuracy: 0.8908 - val_loss: 0.2466 - val_accuracy: 0.8939\n",
            "Epoch 105/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2567 - accuracy: 0.8916 - val_loss: 0.2435 - val_accuracy: 0.8953\n",
            "Epoch 106/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2847 - accuracy: 0.8798 - val_loss: 0.2439 - val_accuracy: 0.8948\n",
            "Epoch 107/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2728 - accuracy: 0.8833 - val_loss: 0.2421 - val_accuracy: 0.8951\n",
            "Epoch 108/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2565 - accuracy: 0.8968 - val_loss: 0.2491 - val_accuracy: 0.8959\n",
            "Epoch 109/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2769 - accuracy: 0.8857 - val_loss: 0.2482 - val_accuracy: 0.8948\n",
            "Epoch 110/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2636 - accuracy: 0.8890 - val_loss: 0.2437 - val_accuracy: 0.8925\n",
            "Epoch 111/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2682 - accuracy: 0.8888 - val_loss: 0.2442 - val_accuracy: 0.8990\n",
            "Epoch 112/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2684 - accuracy: 0.8883 - val_loss: 0.2452 - val_accuracy: 0.8920\n",
            "Epoch 113/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2640 - accuracy: 0.8860 - val_loss: 0.2447 - val_accuracy: 0.8976\n",
            "Epoch 114/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2703 - accuracy: 0.8910 - val_loss: 0.2520 - val_accuracy: 0.8965\n",
            "Epoch 115/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2538 - accuracy: 0.8966 - val_loss: 0.2465 - val_accuracy: 0.8945\n",
            "Epoch 116/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2722 - accuracy: 0.8913 - val_loss: 0.2423 - val_accuracy: 0.8945\n",
            "Epoch 117/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2732 - accuracy: 0.8939 - val_loss: 0.2459 - val_accuracy: 0.8942\n",
            "Epoch 118/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2610 - accuracy: 0.8981 - val_loss: 0.2458 - val_accuracy: 0.8953\n",
            "Epoch 119/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2726 - accuracy: 0.8906 - val_loss: 0.2463 - val_accuracy: 0.8928\n",
            "Epoch 120/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2694 - accuracy: 0.8900 - val_loss: 0.2435 - val_accuracy: 0.8968\n",
            "Epoch 121/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2801 - accuracy: 0.8969 - val_loss: 0.2432 - val_accuracy: 0.8911\n",
            "Epoch 122/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2554 - accuracy: 0.8925 - val_loss: 0.2553 - val_accuracy: 0.8962\n",
            "Epoch 123/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2716 - accuracy: 0.8870 - val_loss: 0.2428 - val_accuracy: 0.8920\n",
            "Epoch 124/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2715 - accuracy: 0.8907 - val_loss: 0.2452 - val_accuracy: 0.8968\n",
            "Epoch 125/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2692 - accuracy: 0.8888 - val_loss: 0.2419 - val_accuracy: 0.8914\n",
            "Epoch 126/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2739 - accuracy: 0.8912 - val_loss: 0.2430 - val_accuracy: 0.8953\n",
            "Epoch 127/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2556 - accuracy: 0.8954 - val_loss: 0.2481 - val_accuracy: 0.8953\n",
            "Epoch 128/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2578 - accuracy: 0.8946 - val_loss: 0.2428 - val_accuracy: 0.8948\n",
            "Epoch 129/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2616 - accuracy: 0.8972 - val_loss: 0.2508 - val_accuracy: 0.8979\n",
            "Epoch 130/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2603 - accuracy: 0.8882 - val_loss: 0.2461 - val_accuracy: 0.8914\n",
            "Epoch 131/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2632 - accuracy: 0.8914 - val_loss: 0.2488 - val_accuracy: 0.8959\n",
            "Epoch 132/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2611 - accuracy: 0.8964 - val_loss: 0.2509 - val_accuracy: 0.8948\n",
            "Epoch 133/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2666 - accuracy: 0.8843 - val_loss: 0.2460 - val_accuracy: 0.8956\n",
            "Epoch 134/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2644 - accuracy: 0.8911 - val_loss: 0.2435 - val_accuracy: 0.8937\n",
            "Epoch 135/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2769 - accuracy: 0.8868 - val_loss: 0.2437 - val_accuracy: 0.8925\n",
            "Epoch 136/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2654 - accuracy: 0.8865 - val_loss: 0.2503 - val_accuracy: 0.8982\n",
            "Epoch 137/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2517 - accuracy: 0.8998 - val_loss: 0.2477 - val_accuracy: 0.8973\n",
            "Epoch 138/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2708 - accuracy: 0.8888 - val_loss: 0.2451 - val_accuracy: 0.8959\n",
            "Epoch 139/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2694 - accuracy: 0.8878 - val_loss: 0.2433 - val_accuracy: 0.8922\n",
            "Epoch 140/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2615 - accuracy: 0.8897 - val_loss: 0.2455 - val_accuracy: 0.8962\n",
            "Epoch 141/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2695 - accuracy: 0.8878 - val_loss: 0.2507 - val_accuracy: 0.8962\n",
            "Epoch 142/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2636 - accuracy: 0.8962 - val_loss: 0.2494 - val_accuracy: 0.8973\n",
            "Epoch 143/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2649 - accuracy: 0.8855 - val_loss: 0.2524 - val_accuracy: 0.8965\n",
            "Epoch 144/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2700 - accuracy: 0.8903 - val_loss: 0.2461 - val_accuracy: 0.8976\n",
            "Epoch 145/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2720 - accuracy: 0.8906 - val_loss: 0.2501 - val_accuracy: 0.8956\n",
            "Epoch 146/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2725 - accuracy: 0.8923 - val_loss: 0.2439 - val_accuracy: 0.8900\n",
            "Epoch 147/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2605 - accuracy: 0.8955 - val_loss: 0.2444 - val_accuracy: 0.8928\n",
            "Epoch 148/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2773 - accuracy: 0.8874 - val_loss: 0.2452 - val_accuracy: 0.8959\n",
            "Epoch 149/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2768 - accuracy: 0.8854 - val_loss: 0.2446 - val_accuracy: 0.8937\n",
            "Epoch 150/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2666 - accuracy: 0.8930 - val_loss: 0.2450 - val_accuracy: 0.8931\n",
            "Epoch 151/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2545 - accuracy: 0.8952 - val_loss: 0.2480 - val_accuracy: 0.8965\n",
            "Epoch 152/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2796 - accuracy: 0.8873 - val_loss: 0.2467 - val_accuracy: 0.8934\n",
            "Epoch 153/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2841 - accuracy: 0.8854 - val_loss: 0.2435 - val_accuracy: 0.8914\n",
            "Epoch 154/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2650 - accuracy: 0.8937 - val_loss: 0.2479 - val_accuracy: 0.8953\n",
            "Epoch 155/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2649 - accuracy: 0.8868 - val_loss: 0.2427 - val_accuracy: 0.8925\n",
            "Epoch 156/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2671 - accuracy: 0.8904 - val_loss: 0.2513 - val_accuracy: 0.8951\n",
            "Epoch 157/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2657 - accuracy: 0.8925 - val_loss: 0.2489 - val_accuracy: 0.8959\n",
            "Epoch 158/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2681 - accuracy: 0.8882 - val_loss: 0.2459 - val_accuracy: 0.8951\n",
            "Epoch 159/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2738 - accuracy: 0.8910 - val_loss: 0.2420 - val_accuracy: 0.8925\n",
            "Epoch 160/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2684 - accuracy: 0.8912 - val_loss: 0.2547 - val_accuracy: 0.8968\n",
            "Epoch 161/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2571 - accuracy: 0.8951 - val_loss: 0.2431 - val_accuracy: 0.8920\n",
            "Epoch 162/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2779 - accuracy: 0.8890 - val_loss: 0.2488 - val_accuracy: 0.8965\n",
            "Epoch 163/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2743 - accuracy: 0.8855 - val_loss: 0.2508 - val_accuracy: 0.8942\n",
            "Epoch 164/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2681 - accuracy: 0.8889 - val_loss: 0.2425 - val_accuracy: 0.8976\n",
            "Epoch 165/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2825 - accuracy: 0.8876 - val_loss: 0.2423 - val_accuracy: 0.8914\n",
            "Epoch 166/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2662 - accuracy: 0.8905 - val_loss: 0.2419 - val_accuracy: 0.8931\n",
            "Epoch 167/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2772 - accuracy: 0.8890 - val_loss: 0.2435 - val_accuracy: 0.8920\n",
            "Epoch 168/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2591 - accuracy: 0.8908 - val_loss: 0.2466 - val_accuracy: 0.8948\n",
            "Epoch 169/1000\n",
            "259/259 [==============================] - 1s 4ms/step - loss: 0.2673 - accuracy: 0.8922 - val_loss: 0.2439 - val_accuracy: 0.8894\n",
            "Epoch 170/1000\n",
            "259/259 [==============================] - 1s 4ms/step - loss: 0.2604 - accuracy: 0.8940 - val_loss: 0.2448 - val_accuracy: 0.8970\n",
            "Epoch 171/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2668 - accuracy: 0.8880 - val_loss: 0.2472 - val_accuracy: 0.8962\n",
            "Epoch 172/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2647 - accuracy: 0.8916 - val_loss: 0.2448 - val_accuracy: 0.8920\n",
            "Epoch 173/1000\n",
            "259/259 [==============================] - 1s 4ms/step - loss: 0.2632 - accuracy: 0.8896 - val_loss: 0.2452 - val_accuracy: 0.8939\n",
            "Epoch 174/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2686 - accuracy: 0.8914 - val_loss: 0.2486 - val_accuracy: 0.8959\n",
            "Epoch 175/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2679 - accuracy: 0.8855 - val_loss: 0.2454 - val_accuracy: 0.8976\n",
            "Epoch 176/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2726 - accuracy: 0.8896 - val_loss: 0.2441 - val_accuracy: 0.8970\n",
            "Epoch 177/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2486 - accuracy: 0.8948 - val_loss: 0.2445 - val_accuracy: 0.8931\n",
            "Epoch 178/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2666 - accuracy: 0.8927 - val_loss: 0.2462 - val_accuracy: 0.8965\n",
            "Epoch 179/1000\n",
            "259/259 [==============================] - 1s 4ms/step - loss: 0.2656 - accuracy: 0.8868 - val_loss: 0.2468 - val_accuracy: 0.8951\n",
            "Epoch 180/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2816 - accuracy: 0.8870 - val_loss: 0.2444 - val_accuracy: 0.8942\n",
            "Epoch 181/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2653 - accuracy: 0.8906 - val_loss: 0.2441 - val_accuracy: 0.8894\n",
            "Epoch 182/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2702 - accuracy: 0.8833 - val_loss: 0.2433 - val_accuracy: 0.8903\n",
            "Epoch 183/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2680 - accuracy: 0.8908 - val_loss: 0.2439 - val_accuracy: 0.8911\n",
            "Epoch 184/1000\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.2741 - accuracy: 0.8867 - val_loss: 0.2469 - val_accuracy: 0.8959\n",
            "Epoch 185/1000\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.2665 - accuracy: 0.8876 - val_loss: 0.2428 - val_accuracy: 0.8951\n",
            "Epoch 186/1000\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.2670 - accuracy: 0.8911 - val_loss: 0.2476 - val_accuracy: 0.8979\n",
            "Epoch 187/1000\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.2809 - accuracy: 0.8814 - val_loss: 0.2461 - val_accuracy: 0.8951\n",
            "Epoch 188/1000\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.2698 - accuracy: 0.8935 - val_loss: 0.2432 - val_accuracy: 0.8911\n",
            "Epoch 189/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2733 - accuracy: 0.8909 - val_loss: 0.2496 - val_accuracy: 0.8939\n",
            "Epoch 190/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2660 - accuracy: 0.8922 - val_loss: 0.2453 - val_accuracy: 0.8951\n",
            "Epoch 191/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2641 - accuracy: 0.8942 - val_loss: 0.2421 - val_accuracy: 0.8925\n",
            "Epoch 192/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2616 - accuracy: 0.8938 - val_loss: 0.2422 - val_accuracy: 0.8920\n",
            "Epoch 193/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2692 - accuracy: 0.8890 - val_loss: 0.2424 - val_accuracy: 0.8959\n",
            "Epoch 194/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2573 - accuracy: 0.8965 - val_loss: 0.2432 - val_accuracy: 0.8914\n",
            "Epoch 195/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2625 - accuracy: 0.8919 - val_loss: 0.2437 - val_accuracy: 0.8914\n",
            "Epoch 196/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2671 - accuracy: 0.8881 - val_loss: 0.2451 - val_accuracy: 0.8948\n",
            "Epoch 197/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2716 - accuracy: 0.8874 - val_loss: 0.2413 - val_accuracy: 0.8906\n",
            "Epoch 198/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2676 - accuracy: 0.8910 - val_loss: 0.2445 - val_accuracy: 0.8962\n",
            "Epoch 199/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2726 - accuracy: 0.8841 - val_loss: 0.2419 - val_accuracy: 0.8942\n",
            "Epoch 200/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2589 - accuracy: 0.8900 - val_loss: 0.2413 - val_accuracy: 0.8920\n",
            "Epoch 201/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2652 - accuracy: 0.8881 - val_loss: 0.2418 - val_accuracy: 0.8968\n",
            "Epoch 202/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2726 - accuracy: 0.8866 - val_loss: 0.2490 - val_accuracy: 0.8925\n",
            "Epoch 203/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2677 - accuracy: 0.8896 - val_loss: 0.2513 - val_accuracy: 0.8956\n",
            "Epoch 204/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2691 - accuracy: 0.8908 - val_loss: 0.2428 - val_accuracy: 0.8922\n",
            "Epoch 205/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2651 - accuracy: 0.8897 - val_loss: 0.2422 - val_accuracy: 0.8914\n",
            "Epoch 206/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2714 - accuracy: 0.8819 - val_loss: 0.2441 - val_accuracy: 0.8920\n",
            "Epoch 207/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2729 - accuracy: 0.8865 - val_loss: 0.2446 - val_accuracy: 0.8917\n",
            "Epoch 208/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2654 - accuracy: 0.8949 - val_loss: 0.2440 - val_accuracy: 0.8973\n",
            "Epoch 209/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2810 - accuracy: 0.8879 - val_loss: 0.2422 - val_accuracy: 0.8951\n",
            "Epoch 210/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2651 - accuracy: 0.8900 - val_loss: 0.2428 - val_accuracy: 0.8903\n",
            "Epoch 211/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2568 - accuracy: 0.8938 - val_loss: 0.2431 - val_accuracy: 0.8920\n",
            "Epoch 212/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2659 - accuracy: 0.8891 - val_loss: 0.2438 - val_accuracy: 0.8951\n",
            "Epoch 213/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2708 - accuracy: 0.8859 - val_loss: 0.2434 - val_accuracy: 0.8922\n",
            "Epoch 214/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2557 - accuracy: 0.8934 - val_loss: 0.2459 - val_accuracy: 0.8973\n",
            "Epoch 215/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2522 - accuracy: 0.8958 - val_loss: 0.2442 - val_accuracy: 0.8951\n",
            "Epoch 216/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2582 - accuracy: 0.8897 - val_loss: 0.2419 - val_accuracy: 0.8917\n",
            "Epoch 217/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2643 - accuracy: 0.8923 - val_loss: 0.2431 - val_accuracy: 0.8942\n",
            "Epoch 218/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2684 - accuracy: 0.8905 - val_loss: 0.2459 - val_accuracy: 0.8922\n",
            "Epoch 219/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2635 - accuracy: 0.8951 - val_loss: 0.2423 - val_accuracy: 0.8948\n",
            "Epoch 220/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2683 - accuracy: 0.8912 - val_loss: 0.2413 - val_accuracy: 0.8934\n",
            "Epoch 221/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2768 - accuracy: 0.8876 - val_loss: 0.2447 - val_accuracy: 0.8951\n",
            "Epoch 222/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2645 - accuracy: 0.8862 - val_loss: 0.2418 - val_accuracy: 0.8948\n",
            "Epoch 223/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2641 - accuracy: 0.8896 - val_loss: 0.2448 - val_accuracy: 0.8934\n",
            "Epoch 224/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2660 - accuracy: 0.8924 - val_loss: 0.2438 - val_accuracy: 0.8951\n",
            "Epoch 225/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2613 - accuracy: 0.8943 - val_loss: 0.2466 - val_accuracy: 0.8956\n",
            "Epoch 226/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2661 - accuracy: 0.8914 - val_loss: 0.2421 - val_accuracy: 0.8948\n",
            "Epoch 227/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2662 - accuracy: 0.8866 - val_loss: 0.2436 - val_accuracy: 0.8951\n",
            "Epoch 228/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2579 - accuracy: 0.8925 - val_loss: 0.2449 - val_accuracy: 0.8931\n",
            "Epoch 229/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2672 - accuracy: 0.8849 - val_loss: 0.2469 - val_accuracy: 0.8982\n",
            "Epoch 230/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2690 - accuracy: 0.8911 - val_loss: 0.2435 - val_accuracy: 0.8939\n",
            "Epoch 231/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2626 - accuracy: 0.8870 - val_loss: 0.2449 - val_accuracy: 0.8920\n",
            "Epoch 232/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2651 - accuracy: 0.8933 - val_loss: 0.2459 - val_accuracy: 0.8922\n",
            "Epoch 233/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2787 - accuracy: 0.8872 - val_loss: 0.2427 - val_accuracy: 0.8948\n",
            "Epoch 234/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2624 - accuracy: 0.8964 - val_loss: 0.2539 - val_accuracy: 0.8970\n",
            "Epoch 235/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2794 - accuracy: 0.8795 - val_loss: 0.2486 - val_accuracy: 0.8962\n",
            "Epoch 236/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2719 - accuracy: 0.8934 - val_loss: 0.2440 - val_accuracy: 0.8908\n",
            "Epoch 237/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2589 - accuracy: 0.8927 - val_loss: 0.2479 - val_accuracy: 0.8939\n",
            "Epoch 238/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2672 - accuracy: 0.8898 - val_loss: 0.2471 - val_accuracy: 0.8953\n",
            "Epoch 239/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2691 - accuracy: 0.8865 - val_loss: 0.2451 - val_accuracy: 0.8931\n",
            "Epoch 240/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2564 - accuracy: 0.8969 - val_loss: 0.2452 - val_accuracy: 0.8920\n",
            "Epoch 241/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2611 - accuracy: 0.8899 - val_loss: 0.2440 - val_accuracy: 0.8937\n",
            "Epoch 242/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2586 - accuracy: 0.8977 - val_loss: 0.2420 - val_accuracy: 0.8931\n",
            "Epoch 243/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2650 - accuracy: 0.8922 - val_loss: 0.2423 - val_accuracy: 0.8880\n",
            "Epoch 244/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2609 - accuracy: 0.8897 - val_loss: 0.2423 - val_accuracy: 0.8911\n",
            "Epoch 245/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2848 - accuracy: 0.8840 - val_loss: 0.2430 - val_accuracy: 0.8928\n",
            "Epoch 246/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2716 - accuracy: 0.8899 - val_loss: 0.2460 - val_accuracy: 0.8970\n",
            "Epoch 247/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2592 - accuracy: 0.8930 - val_loss: 0.2456 - val_accuracy: 0.8897\n",
            "Epoch 248/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2524 - accuracy: 0.8957 - val_loss: 0.2492 - val_accuracy: 0.8959\n",
            "Epoch 249/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2723 - accuracy: 0.8850 - val_loss: 0.2552 - val_accuracy: 0.8970\n",
            "Epoch 250/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2610 - accuracy: 0.8921 - val_loss: 0.2439 - val_accuracy: 0.8920\n",
            "Epoch 251/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2595 - accuracy: 0.8906 - val_loss: 0.2405 - val_accuracy: 0.8900\n",
            "Epoch 252/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2727 - accuracy: 0.8851 - val_loss: 0.2411 - val_accuracy: 0.8883\n",
            "Epoch 253/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2597 - accuracy: 0.8954 - val_loss: 0.2421 - val_accuracy: 0.8911\n",
            "Epoch 254/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2574 - accuracy: 0.8908 - val_loss: 0.2424 - val_accuracy: 0.8934\n",
            "Epoch 255/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2692 - accuracy: 0.8890 - val_loss: 0.2425 - val_accuracy: 0.8911\n",
            "Epoch 256/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2617 - accuracy: 0.8960 - val_loss: 0.2473 - val_accuracy: 0.8937\n",
            "Epoch 257/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2657 - accuracy: 0.8890 - val_loss: 0.2490 - val_accuracy: 0.8956\n",
            "Epoch 258/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2692 - accuracy: 0.8869 - val_loss: 0.2420 - val_accuracy: 0.8920\n",
            "Epoch 259/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2656 - accuracy: 0.8879 - val_loss: 0.2416 - val_accuracy: 0.8889\n",
            "Epoch 260/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2563 - accuracy: 0.8920 - val_loss: 0.2461 - val_accuracy: 0.8931\n",
            "Epoch 261/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2691 - accuracy: 0.8872 - val_loss: 0.2421 - val_accuracy: 0.8939\n",
            "Epoch 262/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2625 - accuracy: 0.8946 - val_loss: 0.2421 - val_accuracy: 0.8956\n",
            "Epoch 263/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2799 - accuracy: 0.8839 - val_loss: 0.2431 - val_accuracy: 0.8965\n",
            "Epoch 264/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2703 - accuracy: 0.8885 - val_loss: 0.2419 - val_accuracy: 0.8903\n",
            "Epoch 265/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2736 - accuracy: 0.8924 - val_loss: 0.2448 - val_accuracy: 0.8962\n",
            "Epoch 266/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2667 - accuracy: 0.8946 - val_loss: 0.2427 - val_accuracy: 0.8956\n",
            "Epoch 267/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2723 - accuracy: 0.8936 - val_loss: 0.2449 - val_accuracy: 0.8973\n",
            "Epoch 268/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2719 - accuracy: 0.8884 - val_loss: 0.2432 - val_accuracy: 0.8937\n",
            "Epoch 269/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2585 - accuracy: 0.8953 - val_loss: 0.2416 - val_accuracy: 0.8942\n",
            "Epoch 270/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2666 - accuracy: 0.8879 - val_loss: 0.2414 - val_accuracy: 0.8903\n",
            "Epoch 271/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2555 - accuracy: 0.8931 - val_loss: 0.2434 - val_accuracy: 0.8934\n",
            "Epoch 272/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2633 - accuracy: 0.8930 - val_loss: 0.2485 - val_accuracy: 0.8953\n",
            "Epoch 273/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2696 - accuracy: 0.8901 - val_loss: 0.2483 - val_accuracy: 0.8928\n",
            "Epoch 274/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2745 - accuracy: 0.8884 - val_loss: 0.2448 - val_accuracy: 0.8937\n",
            "Epoch 275/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2672 - accuracy: 0.8923 - val_loss: 0.2428 - val_accuracy: 0.8953\n",
            "Epoch 276/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2762 - accuracy: 0.8832 - val_loss: 0.2425 - val_accuracy: 0.8917\n",
            "Epoch 277/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2626 - accuracy: 0.8924 - val_loss: 0.2418 - val_accuracy: 0.8903\n",
            "Epoch 278/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2585 - accuracy: 0.8951 - val_loss: 0.2458 - val_accuracy: 0.8976\n",
            "Epoch 279/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2743 - accuracy: 0.8854 - val_loss: 0.2506 - val_accuracy: 0.8990\n",
            "Epoch 280/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2567 - accuracy: 0.8917 - val_loss: 0.2437 - val_accuracy: 0.8922\n",
            "Epoch 281/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2646 - accuracy: 0.8912 - val_loss: 0.2417 - val_accuracy: 0.8920\n",
            "Epoch 282/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2671 - accuracy: 0.8877 - val_loss: 0.2458 - val_accuracy: 0.8945\n",
            "Epoch 283/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2654 - accuracy: 0.8879 - val_loss: 0.2407 - val_accuracy: 0.8925\n",
            "Epoch 284/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2606 - accuracy: 0.8868 - val_loss: 0.2415 - val_accuracy: 0.8922\n",
            "Epoch 285/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2616 - accuracy: 0.8896 - val_loss: 0.2458 - val_accuracy: 0.8979\n",
            "Epoch 286/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2629 - accuracy: 0.8960 - val_loss: 0.2407 - val_accuracy: 0.8889\n",
            "Epoch 287/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2742 - accuracy: 0.8885 - val_loss: 0.2427 - val_accuracy: 0.8931\n",
            "Epoch 288/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2664 - accuracy: 0.8893 - val_loss: 0.2432 - val_accuracy: 0.8937\n",
            "Epoch 289/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2683 - accuracy: 0.8944 - val_loss: 0.2446 - val_accuracy: 0.8891\n",
            "Epoch 290/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2663 - accuracy: 0.8888 - val_loss: 0.2443 - val_accuracy: 0.8880\n",
            "Epoch 291/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2681 - accuracy: 0.8914 - val_loss: 0.2459 - val_accuracy: 0.8959\n",
            "Epoch 292/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2743 - accuracy: 0.8879 - val_loss: 0.2454 - val_accuracy: 0.8925\n",
            "Epoch 293/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2677 - accuracy: 0.8902 - val_loss: 0.2433 - val_accuracy: 0.8937\n",
            "Epoch 294/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2677 - accuracy: 0.8910 - val_loss: 0.2432 - val_accuracy: 0.8925\n",
            "Epoch 295/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2676 - accuracy: 0.8948 - val_loss: 0.2464 - val_accuracy: 0.8951\n",
            "Epoch 296/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2667 - accuracy: 0.8899 - val_loss: 0.2434 - val_accuracy: 0.8951\n",
            "Epoch 297/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2729 - accuracy: 0.8897 - val_loss: 0.2443 - val_accuracy: 0.8945\n",
            "Epoch 298/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2630 - accuracy: 0.8949 - val_loss: 0.2435 - val_accuracy: 0.8914\n",
            "Epoch 299/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2632 - accuracy: 0.8889 - val_loss: 0.2423 - val_accuracy: 0.8956\n",
            "Epoch 300/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2661 - accuracy: 0.8920 - val_loss: 0.2430 - val_accuracy: 0.8934\n",
            "Epoch 301/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2642 - accuracy: 0.8880 - val_loss: 0.2434 - val_accuracy: 0.8965\n",
            "Epoch 302/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2625 - accuracy: 0.8894 - val_loss: 0.2421 - val_accuracy: 0.8928\n",
            "Epoch 303/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2759 - accuracy: 0.8897 - val_loss: 0.2419 - val_accuracy: 0.8928\n",
            "Epoch 304/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2604 - accuracy: 0.8916 - val_loss: 0.2423 - val_accuracy: 0.8939\n",
            "Epoch 305/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2707 - accuracy: 0.8866 - val_loss: 0.2419 - val_accuracy: 0.8925\n",
            "Epoch 306/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2520 - accuracy: 0.8961 - val_loss: 0.2424 - val_accuracy: 0.8973\n",
            "Epoch 307/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2752 - accuracy: 0.8856 - val_loss: 0.2428 - val_accuracy: 0.8939\n",
            "Epoch 308/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2687 - accuracy: 0.8936 - val_loss: 0.2439 - val_accuracy: 0.8973\n",
            "Epoch 309/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2687 - accuracy: 0.8925 - val_loss: 0.2423 - val_accuracy: 0.8959\n",
            "Epoch 310/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2656 - accuracy: 0.8907 - val_loss: 0.2426 - val_accuracy: 0.8922\n",
            "Epoch 311/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2789 - accuracy: 0.8863 - val_loss: 0.2439 - val_accuracy: 0.8999\n",
            "Epoch 312/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2652 - accuracy: 0.8926 - val_loss: 0.2424 - val_accuracy: 0.8908\n",
            "Epoch 313/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2653 - accuracy: 0.8894 - val_loss: 0.2402 - val_accuracy: 0.8939\n",
            "Epoch 314/1000\n",
            "259/259 [==============================] - 1s 3ms/step - loss: 0.2652 - accuracy: 0.8902 - val_loss: 0.2429 - val_accuracy: 0.8931\n",
            "1 loop, best of 3: 2min 11s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIzn_U69TAOr"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjvAGpeSA3Pj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "927fff34-abea-40e8-aff2-8b05fbd0f611"
      },
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYzYNoScM_c9",
        "outputId": "f2e3cd82-7988-41fb-8434-571011d560d6"
      },
      "source": [
        "preds = model.predict(X_test_reshaped) # ex: [[0.99], [0.00004], [0.76],...]\r\n",
        "preds = np.round(preds, 0).reshape(preds.shape[0]) # Pembulatan prediksi dan perubahan dimensi ex: [1, 0, 1, ...]\r\n",
        "acc = accuracy_score(y_test, preds)\r\n",
        "# preds.shape\r\n",
        "acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8902679830747532"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maw9HA66TKF5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}